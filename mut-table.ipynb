{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import os\n",
    "import re\n",
    "from tqdm.notebook import tqdm, trange"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Globals\n",
    "\n",
    "A few general variable about where to find stuff. Adapt to your own needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs\n",
    "vpipe_working = 'working' # V-pipe's working directory\n",
    "ww_samples_tsv = f\"{vpipe_working}/samples.wastewateronly.tsv\" # samples TSV file listing the waste water samples\n",
    "\n",
    "# ww_samples_tsv = f\"{vpipe_working}/samples.wastewateronly.lastweek.tsv\" \n",
    "\n",
    "# optionnal:\n",
    "plant_name_tsv = 'ww_plants.tsv' # tsv with names of the plants (or None)\n",
    "\n",
    "# files generated by snv_count_wastewater3\n",
    "muttable_tsv='mutlist.txt'\n",
    "tables_dir='snv_tables'\n",
    "\n",
    "# Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RegEx used to decode plantcode and date from sample name\n",
    "# should return a dict (named groups):\n",
    "#  - plant: the code of the wastewater plant (if plant_name_tsv is provided, it will be looked up for a full name)\n",
    "#  - year, month, day: used to make a time code for the time-serie\n",
    "rxname=re.compile('(?:(?P<plant>\\d+)_(?P<year>20\\d{2})_(?:(?:(?P<month>[01]?\\d)_(?P<day>[0-3]?\\d))|(?:R_(?P<repeat>\\d+))))|^(?P<KLZH>KLZHCo[vV])(?P<KLZHdate>\\d{6})(?:_(?P<KLZHsuffix>\\w+))?|^(?P<BA>B[aA])(?P<BAsam>\\d{6})(?:_(?P<BAdate>20\\d{2}-[01]?\\d-[0-3]?\\d))?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# warning, this table is *1*-based\n",
    "mut=pd.read_csv(muttable_tsv, sep='\\t').astype({'position':'int'})\n",
    "mut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst=pd.read_csv(ww_samples_tsv, sep='\\t', header=None,names=['sample','batch','reads'])\n",
    "lst#.drop('reads')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plants=pd.read_csv(plant_name_tsv, sep='\\t', header=0,index_col='Code') if plant_name_tsv else pd.Dataframe()\n",
    "plants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tally_multicol(tsam,tbat):\n",
    "    # warning that table is *0*-based\n",
    "    basecount=pd.read_csv(f\"working/samples/{tsam}/{tbat}/alignments/basecnt.tsv.gz\", sep='\\t', header=[0,1],index_col=[0,1]).droplevel('ref').T.droplevel('sample').T\n",
    "    basecount['cov']=basecount.apply(sum, axis=1)\n",
    "    # -1 : 1-based to 0-based\n",
    "    r=pd.DataFrame(data=mut.apply(lambda x: pd.Series([x.position, basecount.loc[x.position-1]['cov'], basecount.loc[x.position-1][x.variant]],index=['pos','cov','var']), axis=1)).set_index('pos').stack().T\n",
    "    r.index =  [f'{i}_{j}' for i, j in r.index]\n",
    "    return pd.DataFrame(data={tsam: r})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: create a patchmap in automation once a format has been decided\n",
    "patchmap_basel_date = {\n",
    "\t'Ba210461_24112021':\t'2021-11-24',\n",
    "\t'Ba210449_2021-11-10':\t'2021-11-10',\n",
    "\t'Ba210429_20211027':\t'2021-10-27',\n",
    "\t'Ba210417': \t'2021-10-13',\n",
    "\t'Ba210411': \t'2021-10-06',\n",
    "}\n",
    "\n",
    "def parse_samname(tsam):\n",
    "    date=plantcode=plantname=np.nan\n",
    "    match=rxname.search(tsam)\n",
    "    if match:\n",
    "        import datetime\n",
    "        m=match.groupdict()\n",
    "        if not m['KLZH'] and not m['BA']:\n",
    "            if m['month'] and m['day']:\n",
    "                date=datetime.datetime(int(m['year']),int(m['month']),int(m['day'])).strftime('%Y-%m-%d')\n",
    "            plantcode=int(m['plant'])\n",
    "            plantname=plants.at[plantcode,'Plant'] if plantcode in plants.index else ''\n",
    "        elif m['KLZH']:\n",
    "            #print('>>>>>>>>>>', tsam, m)\n",
    "            date = datetime.datetime.strptime(m['KLZHdate'], '%y%m%d').date().strftime('%Y-%m-%d')\n",
    "            if not m['KLZHsuffix']: # avoid _Promega and _2 \n",
    "                plantname = 'Kanton Zürich'\n",
    "                plantcode = 90\n",
    "            else:\n",
    "                plantname = 'Kanton Zürich/Promega'\n",
    "                plantcode = 91\n",
    "        elif m['BA']:\n",
    "            if tsam in patchmap_basel_date:\n",
    "                date = patchmap_basel_date[tsam]\n",
    "            elif m['BAdate']:\n",
    "                date = datetime.datetime.strptime(m['BAdate'], '%Y-%m-%d').date().strftime('%Y-%m-%d')\n",
    "            #plantname = 'Kanton Basel'\n",
    "            plantname = 'Basel (catchment area ARA Basel)'\n",
    "            plantcode = 92\n",
    "    return (date,plantcode,plantname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tally_multiline(tsam,tbat):\n",
    "    (date,plantcode,plantname) = parse_samname(tsam)\n",
    "    # warning that table is *0*-based\n",
    "    basecount=pd.read_csv(f\"working/samples/{tsam}/{tbat}/alignments/basecnt.tsv.gz\", sep='\\t', header=[0,1],index_col=[0,1]).droplevel('ref').T.droplevel('sample').T\n",
    "    basecount['cov']=basecount.apply(sum, axis=1)\n",
    "    r=pd.DataFrame(data=mut.apply(\n",
    "        lambda x: pd.Series([tsam, tbat, \n",
    "                             date,plantcode,plantname,\n",
    "                             x.gene,x.position,x.variant,\n",
    "                             # -1 : 1-based to 0-based\n",
    "                             basecount.loc[x.position-1]['cov'], \n",
    "                             basecount.loc[x.position-1][x.variant],\n",
    "                             basecount.loc[x.position-1][x.variant]/basecount.loc[x.position-1]['cov'] if \n",
    "                                 basecount.loc[x.position-1]['cov'] else np.nan\n",
    "                            ],index=['sample','batch',\n",
    "                                     'date','plantcode','plantname',\n",
    "                                     'gene','pos','base','cov','var','frac']).append(x[4:]),\n",
    "                            axis=1)).set_index(['sample','batch','pos'])\n",
    "    # testing\n",
    "#     if b:\n",
    "#         print(r)\n",
    "    return r "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tally_filter(tsam,tbat,fdirs):\n",
    "    (date,plantcode,plantname) = parse_samname(tsam)\n",
    "    # warning that table is *0*-based\n",
    "    basecount=pd.read_csv(f\"working/samples/{tsam}/{tbat}/alignments/basecnt.tsv.gz\", sep='\\t', header=[0,1],index_col=[0,1]).droplevel('ref').T.droplevel('sample').T\n",
    "    basecount['cov']=basecount.apply(sum, axis=1)\n",
    "    r={}\n",
    "    for fil_dir in fdirs:\n",
    "        # load ShoRAH-called SNVs\n",
    "        shorah_fname=f\"{fil_dir}_tables/{tsam}-{tbat}_{fil_dir}.csv\"\n",
    "        shorah_snv=None\n",
    "        if os.path.isfile(shorah_fname):\n",
    "            shorah_snv=pd.read_csv(shorah_fname, sep=',', header=0, index_col=0)\n",
    "        else:\n",
    "            # if no table was generated, consider the whole file empty\n",
    "            print(f\"Warning!!! File {shorah_fname} is missing!!!\")\n",
    "            shorah_snv=pd.DataFrame(data=[], columns=['position','candidate_windows','effective_windows','ave_reads'])\n",
    "        # combine ShoRAH-called SNVs and mutation list\n",
    "        fil_snv=pd.merge(left=mut, right=shorah_snv[['position','candidate_windows','effective_windows','ave_reads']],\n",
    "                         # outer: keep even the mutation not in ShoRAH and zero-fill\n",
    "                         how='outer', left_on=\"position\", right_on=\"position\").fillna(0)\n",
    "        # generate output\n",
    "        r[fil_dir]=pd.DataFrame(data=fil_snv.apply(\n",
    "            lambda x: pd.Series([tsam, tbat, \n",
    "                                 date,plantcode,plantname,\n",
    "                                 x.gene,x.position,x.variant,\n",
    "                                 # -1 : 1-based to 0-based\n",
    "                                 basecount.loc[x.position-1]['cov'] if x.candidate_windows > 0 else 0, \n",
    "                                 basecount.loc[x.position-1][x.variant] if x.effective_windows > 0 else 0,\n",
    "                                 (basecount.loc[x.position-1][x.variant] if x.effective_windows > 0 else 0)/basecount.loc[x.position-1]['cov'] if \n",
    "                                     basecount.loc[x.position-1]['cov'] and (x.candidate_windows > 0) else np.nan\n",
    "                                ],index=['sample','batch',\n",
    "                                         'date','plantcode','plantname',\n",
    "                                         'gene','pos','base','cov','var','frac']).append(x[4:-3]),\n",
    "                                axis=1)).set_index(['sample','batch','pos'])\n",
    "        \n",
    "    \n",
    "    return r "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process ShoRAH-filtered data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters_list=['snv'] # single file with all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fdir in filters_list:\n",
    "    assert os.path.isdir(f'{fdir}_tables/')\n",
    "\n",
    "filter_tables={ fdir: pd.DataFrame() for fdir in filters_list }\n",
    "\n",
    "for i,s in tqdm(list(lst.iterrows())):\n",
    "    table=tally_filter(s['sample'],s['batch'],filters_list)\n",
    "    for fdir in filters_list:\n",
    "        filter_tables[fdir]=pd.concat([filter_tables[fdir], table[fdir]], axis=0, join='outer', copy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(filter_tables['snv'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fdir in filters_list:\n",
    "    assert os.path.isdir(f'{fdir}_tables/')\n",
    "    fname=f\"tallymut_line_{fdir}.tsv\"\n",
    "    print(f\"Writing {fname}\")\n",
    "    filter_tables[fdir].to_csv(fname,sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process unfiltered data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table=pd.DataFrame()\n",
    "for i,s in tqdm(list(lst.iterrows())):\n",
    "    #table=pd.concat([table, tally(s['sample'],s['batch'])], axis=1, join='outer', copy=False).T\n",
    "    table=pd.concat([table, tally_multiline(s['sample'],s['batch'])], axis=0, join='outer', copy=False)\n",
    "display(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table[table['plantname'] == 'Kanton Basel'] #Zürich']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = table.reset_index()\n",
    "t[t['sample'] == 'KLZHCov210822']['date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table.to_csv(f\"tallymut_line.tsv\",sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single tests scrap-yard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tally_multiline('A1_12_2020_12_21_NA_NA','20201223_HWKGTDRXX')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tally_filter('A1_12_2020_12_21_NA_NA','20201223_HWKGTDRXX',['snv'])['snv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tally_filter('C1_10_2020_12_11_NA_NA','20201223_HWKGTDRXX',['snv'])['snv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tally_multicol('A1_12_2020_12_21_NA_NA','20201223_HWKGTDRXX').T[['23403_var','23403_cov']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fil_dir='sa_snv'\n",
    "tsam='A1_12_2020_12_21'\n",
    "shorah_snv=pd.read_csv(f\"{fil_dir}_tables/{tsam}_{fil_dir}.csv\", sep=',', header=0, index_col=0)\n",
    "pd.merge(left=mut, right=shorah_snv[['position','candidate_windows','effective_windows','ave_reads']], how='outer', left_on=\"position\", right_on=\"position\").fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rxname=re.compile('(?P<plant>\\d+)_(?P<year>20\\d{2})_(?P<month>[01]?\\d)_(?P<day>[0-3]?\\d)')\n",
    "rxname.search('12_2020_12_21').groupdict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=rxname.search('12_2020_12_21').groupdict()\n",
    "plants.at[int(m['plant']),'Plant']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rxname.search('F1_12_2021_R_02').groupdict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bio1",
   "language": "python",
   "name": "bio1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
