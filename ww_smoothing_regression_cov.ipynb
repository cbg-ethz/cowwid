{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0338a766",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "plotwidth=40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69468433",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "from natsort import natsort_keygen\n",
    "import glob\n",
    "import yaml\n",
    "import numpy as np\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import math\n",
    "from natsort import natsort_keygen\n",
    "import glob\n",
    "import yaml\n",
    "import numpy as np\n",
    "import datetime\n",
    "import statsmodels.api as sm\n",
    "from tqdm.notebook import tqdm, trange\n",
    "from sklearn.utils import resample\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.optimize import nnls\n",
    "from scipy.optimize import minimize\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import glob\n",
    "import time\n",
    "import json\n",
    "import psycopg2\n",
    "import netrc\n",
    "import re\n",
    "import os\n",
    "from multiprocess import Pool\n",
    "\n",
    "lowess = sm.nonparametric.lowess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84cff3d",
   "metadata": {},
   "source": [
    "# Globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30135993",
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = '.'\n",
    "plotdir = 'plots'\n",
    "vpipe_working = 'working' # V-pipe's working directory\n",
    "\n",
    "\n",
    "tally_data = os.path.join(datadir, 'tallymut_line.tsv')\n",
    "plant_name_tsv = pd.read_csv('ww_plants.tsv')\n",
    "heatmaps_json_file = os.path.join(datadir, 'ww_update_data_heatmap.json')\n",
    "\n",
    "#for later\n",
    "# cooc_data = 'data/ww-cooc.csv'\n",
    "\n",
    "start_date = '2020-12-08'\n",
    "todaydate = datetime.date.today().strftime(\"%Y-%m-%d\")\n",
    "cities_list=['Basel (catchment area ARA Basel)', 'Altenrhein (SG)', 'Chur (GR)', 'Genève (GE)', 'Laupen (BE)',\n",
    "       'Lausanne (VD)', 'Lugano (TI)', 'Zürich (ZH)', 'Kanton Zürich', ]\n",
    "cities_list_upload=cities_list #\n",
    "variants_pangolin={'al':'B.1.1.7','be':'B.1.351','ga':'P.1','C36':'C.36.3','ka':'B.1.617.1','de':'B.1.617.2','AY42':'AY.4.2','B16173':'B.1.617.3','om':'B.1.1.529','om2':'omi-BA.2','BA1':'BA.1','BA2':'BA.2'}\n",
    "\n",
    "# variants that will be displayed here AND uploaded:\n",
    "variants_list_upload=['B.1.1.7', 'B.1.351', 'P.1', 'B.1.617.2', 'B.1.617.1', 'B.1.1.529','omi-BA.2',]\n",
    "# extra variants that will be ONLY display here, but NOT uploaded (typically for variant not present yet)\n",
    "variants_list = variants_list_upload#+['']\n",
    "variants_upload = ['undetermined'] + variants_list_upload\n",
    "variants_not_reported = ['BA.1', 'BA.2', 'C.36.3', 'B.1.617.3', 'AY.4.2','mu','d614g']\n",
    "rename_variants = { 'omi-BA.2': 'BA.2'}\n",
    "exclusive_list=['B.1.351','P.1'] # list of variants where we should apply filtering\n",
    "exclude_from=['B.1.1.7','B.1.351','P.1' ] #,'IN2'] #,'C36','IN1','IN2','IN3'] # filter against these variants\n",
    "max_pool = len(cities_list)\n",
    "\n",
    "# mutations type to be considered\n",
    "mut_types = ['mut', 'extra']\n",
    "# drop all shared and subset mutations\n",
    "to_drop = ['subset', 'shared']\n",
    "\n",
    "\n",
    "# Outputs\n",
    "plots_dir='deconv_plots'\n",
    "if not os.path.isdir(plots_dir):\n",
    "    try:\n",
    "        os.mkdir(plots_dir, mode=0o775)\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "update_data_combined_file = os.path.join(datadir, 'ww_update_data_combined.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122cd47f",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd6fbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load tsv into dataframe\n",
    "df_tally = pd.read_csv(tally_data, sep='\\t')\n",
    "df_tally = df_tally.rename(columns=variants_pangolin)\n",
    "df_tally = df_tally.drop(variants_not_reported, axis=1)\n",
    "\n",
    "df_tally.head()\n",
    "#df_tally[(df_tally['plantname'] == 'Altenrhein (SG)') & (df_tally['date'] == '2021-12-26') & \n",
    "#((df_tally['B.1.1.529'] == 'mut') | (df_tally['B.1.1.529'] == 'extra'))].to_csv('Kanton_Basel_mut.csv')\n",
    "df_tally[(df_tally['plantname'] == 'Altenrhein (SG)') & (df_tally['date'] == '2021-12-26') & (df_tally['B.1.1.529'] == 'mut') & (df_tally['pos'] == 22578) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb4afea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = df_tally.copy()\n",
    "df_data.dropna(subset = [\"frac\", \"date\"], inplace=True)\n",
    "df_data['mutations'] = df_data['pos'].astype(str) + df_data['base']\n",
    "\n",
    "df_data = df_data[~(df_data['base'] == '-') & (df_data['date'] >= start_date)]\n",
    "\n",
    "df_data = df_data[df_data.columns.difference(['pos', 'gene', 'base'], sort=False)]\n",
    "\n",
    "print(df_data.shape)\n",
    "# drop other mutation type from df_data\n",
    "for v in variants_list:\n",
    "    df_data = df_data[~df_data[v].isin(to_drop)]\n",
    "\n",
    "df_data = df_data.reset_index(drop=True)\n",
    "\n",
    "mutations =  sorted(list(df_data['mutations'].unique()), key=natsort_keygen())\n",
    "# df_data[df_data['plantname'] == 'Altenrhein (SG)'].sort_values(by='date')\n",
    "\n",
    "# remove problematic mutations\n",
    "df_data = df_data[~df_data[\"mutations\"].isin([\"28461G\", \"11201G\", \"26801C\"])]\n",
    "df_data.head()\n",
    "df_data[df_data['batch'] == '20220110_HKLFGDRXY']['plantname'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13ad148",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data2 = df_data[df_data.columns.difference(['batch'], sort=False)]\n",
    "df_data2 = df_data2.replace(np.nan, 0)\n",
    "df_data2 = df_data2.replace(['extra', 'mut'], 1)\n",
    "df_data2 = df_data2[df_data2.columns.difference(['plantcode', 'cov', 'var'], sort=False)]\n",
    "df_data2 = df_data2.sort_values(by=['date', 'sample'])\n",
    "\n",
    "dates = sorted(set(df_data2['date']), key=natsort_keygen())\n",
    "# df_data2[(df_data2['plantname'] == 'Lugano (TI)') & (df_data2['date'] == '2021-07-20')]\n",
    "df_data2.insert(4, 'undetermined', 0)\n",
    "# sorted(df_data2['date'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d87b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Complement of matrix A (to add undetermined case)\n",
    "data = {'sample':df_data2['sample'], 'date':df_data2['date'], 'plantname':df_data2['plantname'],\n",
    "       'frac':1-df_data2['frac']}\n",
    "data.update({v: 1-df_data2[v] for v in variants_list})\n",
    "data.update({'mutations': '-' + df_data2['mutations'].astype(str)})\n",
    "\n",
    "df_data3 = pd.DataFrame(data)\n",
    "df_data3.insert(4, 'undetermined', 1)\n",
    "df_data3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e359f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data4 = pd.concat([df_data2, df_data3], sort=False)\n",
    "df_data4[df_data4['undetermined'] == 0]\n",
    "mutations =  sorted(list(df_data4['mutations'].unique()), key=natsort_keygen())\n",
    "df_data4[df_data4['B.1.617.2'] == 1]\n",
    "variants = ['undetermined' ] + variants_list\n",
    "variants = sorted(variants)#, key=natsort_keygen())\n",
    "# sorted(df_data4[df_data4['plantname'] == cities_list[2]]['date'].unique())\n",
    "df_data4.head()\n",
    "df_data4.shape\n",
    "# df_data4[(df_data4['plantname'] == 'Basel (catchment area ARA Basel)') & (df_data4['mutations'] == '22578A')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed71713",
   "metadata": {},
   "source": [
    "### Filter out problematic mutations for Omicron in V4/V3 (very temp!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b151af6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data4[\"pos\"] = df_data4.mutations.str.extract(\"([0-9]+)\").astype(\"int\")\n",
    "df_data4[pd.to_datetime(df_data4.date) > np.datetime64(\"2021-11-20\")]\n",
    "df_data4 = df_data4[~((pd.to_datetime(df_data4.date) > np.datetime64(\"2021-11-20\")) & (df_data4.pos >= 22428) & (df_data4.pos <= 22785))] # amplicon75\n",
    "df_data4 = df_data4[~((pd.to_datetime(df_data4.date) > np.datetime64(\"2021-11-20\")) & (df_data4.pos >= 22677) & (df_data4.pos <= 23028))] # amplicon76\n",
    "df_data4 = df_data4[~((pd.to_datetime(df_data4.date) > np.datetime64(\"2021-11-20\")) & (df_data4.pos >= 22974) & (df_data4.pos <= 23327))] # amplicon77\n",
    "df_data4 = df_data4[~((pd.to_datetime(df_data4.date) > np.datetime64(\"2021-11-20\")) & (df_data4.pos >= 26277) & (df_data4.pos <= 26635))] # amplicon88\n",
    "df_data4 = df_data4[~((pd.to_datetime(df_data4.date) > np.datetime64(\"2021-11-20\")) & (df_data4.pos >= 26895) & (df_data4.pos <= 27256))] # amplicon90\n",
    "df_data4 = df_data4[~((pd.to_datetime(df_data4.date) > np.datetime64(\"2021-11-20\")) & (df_data4.pos == 26709))] # other\n",
    "df_data4 = df_data4[~((pd.to_datetime(df_data4.date) > np.datetime64(\"2021-11-20\")) & (df_data4.pos == 27807))] # other\n",
    "df_data4 = df_data4[~((pd.to_datetime(df_data4.date) > np.datetime64(\"2021-11-20\")) & (df_data4.pos == 2832))] # other\n",
    "df_data4 = df_data4[~((pd.to_datetime(df_data4.date) > np.datetime64(\"2021-11-20\")) & (df_data4.pos == 10449))] # other\n",
    "\n",
    "\n",
    "df_data4.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff55433",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data4 = df_data4.drop(\"pos\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2ae410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_data4[(df_data4['plantname'] == 'Basel (catchment area ARA Basel)') & (df_data4['mutations'] == '22674T')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02fc3ee8",
   "metadata": {},
   "source": [
    "# Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29e4d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ineq_cons(x):\n",
    "    \"\"\"constrain all elements of x to be >= 0\"\"\"\n",
    "    return x\n",
    "\n",
    "def eq_cons(x):\n",
    "    \"\"\"constrain the sum of all rows to be equal to 1\"\"\"\n",
    "    return np.sum(x) - 1\n",
    "\n",
    "def fn(x, A, b):\n",
    "    return 0.5*np.linalg.norm(A.dot(x)-b)**2\n",
    "\n",
    "def cal_nnls_ridge2(X,y, lam, l=9):\n",
    "    p = X.shape[1]\n",
    "    Xext = np.vstack((X, lam * np.identity(X.shape[1])))\n",
    "\n",
    "    yext = np.hstack((y, np.zeros(p)))\n",
    "    coefs, _ = nnls(Xext, yext)\n",
    "\n",
    "    cons = [{'type': 'ineq', 'fun': ineq_cons},\n",
    "               {'type': 'eq', 'fun': eq_cons}]\n",
    "\n",
    "    #Call minimisation subject to these values\n",
    "    minout = minimize(fn, coefs, args=(Xext, yext), method='SLSQP',bounds=[(0., None) for i in range(l)]\n",
    "                      ,constraints=cons)\n",
    "\n",
    "    x = minout.x\n",
    "\n",
    "    return x    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e199b5",
   "metadata": {},
   "source": [
    "### Bootstrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1d218b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_mutations(df_city1, mutations):\n",
    "    \"\"\"\n",
    "    Function to resample mutations by replacement (preserving mutation-complement pairs). \n",
    "    Returns a copy of the DataFrame with <resample_value> column indicating how many times the mutation was in the resample.\n",
    "    \"\"\"\n",
    "\n",
    "    # resample indices of mutations with replacement (warning: high is one above actual high!\n",
    "    rand_idcs = np.random.randint(0, high=int(len(mutations)/2), size=int(len(mutations)/2))\n",
    "    # for all mutations, count how many times they appear in the resample (0, 1, 2 ...)\n",
    "    resamples_counts = np.bincount(rand_idcs, minlength=int(len(mutations)/2))\n",
    "    # make a dict of {mutation : occurences in the resample} pairs\n",
    "    resample_coeff_dict = dict(zip(mutations, np.concatenate([resamples_counts, resamples_counts])))\n",
    "    # make a column with coefficients for how many times a row should be accounted for according to the resample\n",
    "    df_sampled = df_city1.copy()\n",
    "    df_sampled.loc[:,\"resample_value\"] = df_sampled.mutations.map(resample_coeff_dict)\n",
    "    \n",
    "    return df_sampled, rand_idcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3160d6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def regress_city(city): # globals: df_data2, df_data4, variants\n",
    "#     current_ridge = []\n",
    "# #     df_city1 = df_data2[(df_data2['plantname'] == city)]\n",
    "#     df_city1 = df_data4[(df_data4['plantname'] == city)]\n",
    "#     dates = sorted(set(df_city1['date']), key=natsort_keygen())\n",
    "\n",
    "#     for n in trange(0,100, desc=city):\n",
    "#         for d in dates:\n",
    "#             muts = np.random.choice(mutations, len(mutations), replace=True)\n",
    "#             df_city_date = df_city1[df_city1['date'] == d]\n",
    "\n",
    "\n",
    "#             df_sampled = df_city_date[df_city_date['mutations'].map(lambda x: x in muts)]\n",
    "            \n",
    "# #             rand_idcs = np.random.randint(0, high=int(len(mutations)/2 -1), size=int(len(mutations)/2 -1))\n",
    "# #             muts_sampled = np.array(mutations)[np.concatenate([rand_idcs, rand_idcs+int(len(mutations)/2)])]\n",
    "            \n",
    "# #             df_sampled = df_city_date[df_city_date.mutations.isin(muts_sampled)]\n",
    "# #             print(df_sampled)\n",
    "\n",
    "\n",
    "\n",
    "#             if len(df_sampled) > 0:\n",
    "#                 df_ridge = df_sampled[df_sampled.columns.difference(['sample', 'date', 'plantname', 'mutations'], \n",
    "#                                                                     sort=False)]\n",
    "\n",
    "#                 char_vars = df_ridge[df_ridge.columns.difference(['sample', 'date','plantname',\n",
    "#                                                                           'frac', 'mutations', 'date'])].columns.values\n",
    "\n",
    "#                 for value, variant in zip(cal_nnls_ridge2(np.array(df_ridge[variants]), np.array(df_ridge['frac']), \n",
    "#                                                           0.5, len(char_vars)), char_vars):\n",
    "#                         current_ridge.append([variant, value, city, d, n])\n",
    "#     return current_ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97605544",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regress_city(city): # globals: df_data2, df_data4, variants\n",
    "    current_ridge = []\n",
    "#     df_city1 = df_data2[(df_data2['plantname'] == city)]\n",
    "    df_city1 = df_data4[(df_data4['plantname'] == city)]\n",
    "    dates = sorted(set(df_city1['date']), key=natsort_keygen())\n",
    "#     print(variants)\n",
    "\n",
    "    for n in trange(0,100, desc=city):\n",
    "        for d in dates:\n",
    "            muts = np.random.choice(mutations, len(mutations), replace=True)\n",
    "            df_city_date = df_city1[df_city1['date'] == d]\n",
    "\n",
    "\n",
    "#             df_sampled = df_city_date[df_city_date['mutations'].map(lambda x: x in muts)]\n",
    "            \n",
    "            df_sampled,_ = resample_mutations(df_city_date, mutations)\n",
    "\n",
    "            if len(df_sampled) > 0:\n",
    "                df_ridge = df_sampled[df_sampled.columns.difference(['sample', 'date', 'plantname', \n",
    "                                                                     'mutations', 'resample_value'], sort=False)]\n",
    "\n",
    "                char_vars = df_ridge[df_ridge.columns.difference(['sample', 'date','plantname', 'frac', \n",
    "                                                                  'mutations', 'resample_value' ,'date'])].columns.values\n",
    "\n",
    "                for value, variant in zip(cal_nnls_ridge2(np.array(df_ridge[variants]) * np.expand_dims(df_sampled[\"resample_value\"].values, 1),\n",
    "                                                          np.array(df_ridge['frac']) * df_sampled[\"resample_value\"].values,\n",
    "                                                          0.5, len(char_vars)), char_vars):\n",
    "                        current_ridge.append([variant, value, city, d, n])\n",
    "    return current_ridge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca5061b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_res=[]\n",
    "# city_ex = [cities_list[0]]#for testing\n",
    "\n",
    "#with Pool(max_pool) as p:\n",
    "#    global df_data2, df_data4, variants\n",
    "#    pool_res = list(\n",
    "#        tqdm(\n",
    "#            p.imap(regress_city,\n",
    "#                   cities_list),\n",
    "#            total=len(cities_list)\n",
    "#        )\n",
    "#    )\n",
    "#for res in pool_res:\n",
    "#    ridge_res += res\n",
    "\n",
    "for city in tqdm(cities_list, desc='Cities', position=0):\n",
    "    ridge_res += regress_city(city)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281323ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load regression coefs to dataframe\n",
    "df_ridge_res = pd.DataFrame(ridge_res)\n",
    "df_ridge_res = df_ridge_res.rename(columns={0: 'variant', 1: 'weight', 2: 'location', 3: 'date', 4: 'iter'})\n",
    "df_ridge_res['date'] = pd.to_datetime(df_ridge_res['date'])\n",
    "\n",
    "df_final = df_ridge_res.sort_values(by=['date','variant']).reset_index(drop=True)\n",
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec0249a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ridge_res.to_csv('df_ridge_res.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8e74aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prefinal = df_final.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed4f7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df13c9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_prefinal.copy()\n",
    "\n",
    "# TODO: have an actual classifier instead of mannually assigning presence \n",
    "df_final.loc[(df_final[\"variant\"]==\"B.1.1.529\") & (df_final[\"date\"]<np.datetime64(\"2021-11-01\")),\"weight\"] = 0.0\n",
    "df_final.loc[(df_final[\"variant\"]=='omi-BA.2') & (df_final[\"date\"]<np.datetime64(\"2021-11-01\")),\"weight\"] = 0.0\n",
    "#df_final.loc[(df_final[\"variant\"]==\"B.1.1.529\") & (df_final[\"location\"]!=\"Basel (catchment area ARA Basel)\"),\"weight\"] = 0.0\n",
    "# df_final.loc[(df_final[\"variant\"]==\"B.1.1.529\") & (df_final[\"location\"].isin([\"Altenrhein (SG)\"])),\"weight\"] = 0.0\n",
    "df_final[(df_final['location'] == 'Basel (catchment area ARA Basel)') & (df_final['variant'] == 'B.1.1.529') & (df_final['date'] == '2021-10-15')]\n",
    "# df_final = df_final[(df_final['date'] > '2021-11-14') & (df_final['date'] < '2022-01-02')]\n",
    "# df_final = df_final[(df_final['date'] > '2021-11-14') & (df_final['date'] < '2021-12-02')]\n",
    "df_final[(df_final['location'] == 'Basel (catchment area ARA Basel)') & (df_final['variant'] == 'B.1.1.529')]\n",
    "\n",
    "df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6fc163c",
   "metadata": {},
   "source": [
    "# Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcd2680",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Smoothing\n",
    "agg={}\n",
    "agg2={}\n",
    "agg3={}\n",
    "df_smooth1={}\n",
    "df_smooth2={}\n",
    "d_test={}\n",
    "#city_ex =[cities_list[0], cities_list[3]]\n",
    "print(variants)\n",
    "for city in tqdm(cities_list, desc='Cities', position=0):\n",
    "    agg[city]={}\n",
    "    agg2[city]={}\n",
    "    agg3[city]={}\n",
    "    df_smooth1[city]={}\n",
    "    df_smooth2[city]={}\n",
    "    d_test[city]={}\n",
    "\n",
    "    for var in tqdm(variants, desc=city, position=1, leave=False):\n",
    "\n",
    "        df_smooth1[city][var] = df_final[(df_final['location'] == city) & (df_final['variant'] == var)]\n",
    "\n",
    "        df_smooth1[city][var] = df_smooth1[city][var].groupby(['variant', 'location', 'date'])['weight'].apply(list)\n",
    "\n",
    "        df_smooth2[city][var] = df_smooth1[city][var].apply(pd.Series)\n",
    "\n",
    "        agg2[city][var] = df_smooth2[city][var].reset_index()\n",
    "        agg3[city][var] = (df_smooth2[city][var].apply(lambda x: lowess(x, np.arange(x.shape[0]).astype('float64'),\n",
    "                                                            xvals = np.arange(x.shape[0]).astype('float64'),\n",
    "                                                            frac= np.clip(20./df_smooth2[city][var].shape[0], 0, 2./3), it=0), 0)\n",
    "                          ) if city != 'Kanton Basel' else (\n",
    "                            # For KLZH data\n",
    "                           df_smooth2[city][var].apply(lambda x: x.rolling(window=2, min_periods=1).mean(), 0)\n",
    "                          )  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41babd6d",
   "metadata": {},
   "source": [
    "# Prevalence Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e7b3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# show all variants separately\n",
    "sns.set_palette(\"dark\")\n",
    "# variants = sorted(variants, key=natsort_keygen())\n",
    "for city in tqdm(cities_list, desc='Cities', position=0):\n",
    "\n",
    "    #print(city)\n",
    "    #fig = plt.figure()\n",
    "    #fig, ax = plt.subplots(nrows=1, figsize=(20, 10), sharex=False)\n",
    "    #ax = [ax]\n",
    "\n",
    "    for var in tqdm(variants, desc=city, position=1, leave=False):\n",
    "\n",
    "        fig = plt.figure()\n",
    "        fig, ax = plt.subplots(nrows=1, figsize=(12, 5), sharex=False)\n",
    "        ax = [ax]\n",
    "\n",
    "        # TODO be more clever with amplicons (for now we're just ignoring them)\n",
    "        xvals = sorted(list(set(agg2[city][var]['date'])))\n",
    "\n",
    "\n",
    "        sns.lineplot(x=xvals, y=np.clip(agg3[city][var].apply(np.nanmean, 1), 0., 1.),\n",
    "                     ax=ax[0], markers=True,linewidth=3)\n",
    "\n",
    "        ax[0].fill_between(xvals,\n",
    "                           np.clip(agg3[city][var].apply(lambda x: np.percentile(x, 5), 1).interpolate(), 0, 1),\n",
    "                           np.clip(agg3[city][var].apply(lambda x: np.percentile(x, 95), 1).interpolate(), 0, 1),\n",
    "                           alpha=.4)\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        ax[0].set_xlim((np.datetime64(start_date), np.datetime64(todaydate)))\n",
    "    \n",
    "        ax[0].set_ylabel(f\"coeffs\")\n",
    "        ax[0].legend(loc=\"upper left\")\n",
    "        ax[0].set_title(f\"{city}/{var}: smoothed regression curve\")\n",
    "        \n",
    "\n",
    "\n",
    "#         plt.savefig(os.path.join(plots_dir, f'{city}_{var}.png')\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932b0d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show all variants at the same time\n",
    "sns.set_palette(\"dark\")\n",
    "# variants = sorted(variants, key=natsort_keygen())\n",
    "\n",
    "for city in tqdm(cities_list, desc='Cities', position=0):\n",
    "\n",
    "    fig = plt.figure()\n",
    "    fig, ax = plt.subplots(nrows=1, figsize=(20, 10), sharex=False)\n",
    "    ax = [ax]\n",
    "    l = 1\n",
    "    for var in tqdm(variants, desc=city, position=1, leave=False):\n",
    "        \n",
    "#         if var == 'B.1.617.2':\n",
    "#             l = 4\n",
    "            \n",
    "#         elif var == 'B.1.1.529':\n",
    "#             l = 1\n",
    "        \n",
    "#         else:\n",
    "#             l = 1\n",
    "\n",
    "        # TODO be more clever with amplicons (for now we're just ignoring them)\n",
    "        xvals = sorted(list(set(agg2[city][var]['date'])))\n",
    "        \n",
    "\n",
    "\n",
    "        sns.lineplot(x=xvals, y=np.clip(agg3[city][var].apply(np.nanmean, 1), 0., 1.),\n",
    "                     ax=ax[0], markers=True, label=var, linewidth=l)\n",
    "\n",
    "#         ax[0].fill_between(xvals,\n",
    "#                            np.clip(agg3[city][var].apply(lambda x: np.percentile(x, 5), 1).interpolate(), 0, 1),\n",
    "#                            np.clip(agg3[city][var].apply(lambda x: np.percentile(x, 95), 1).interpolate(), 0, 1),\n",
    "#                            alpha=.4)\n",
    "\n",
    "        ax[0].set_xlim((np.datetime64(start_date), np.datetime64(todaydate)))\n",
    "        ax[0].set_ylabel(f\"coeffs\")\n",
    "#         ax[0].legend(loc=\"upper left\")\n",
    "        ax[0].set_title(f\"{city}: smoothed regression curve\")\n",
    "    plt.savefig(os.path.join(plots_dir, f\"{city.replace('/','-')}.png\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3fb1c8",
   "metadata": {},
   "source": [
    "# Prepare data for upload\n",
    "\n",
    "## Load heatmap json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9730fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from IPython.display import JSON\n",
    "\n",
    "old_json=heatmaps_json_file\n",
    "# print(\"reusing %s last modified: %s\" % (old_json, time.ctime(os.path.getmtime(old_json))))\n",
    "with open(old_json, 'r') as file:\n",
    "     old_data = json.load(file)\n",
    "#JSON(old_update_data) # only in Jupyter Lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7023cb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_data['undetermined']['Altenrhein (SG)'].keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3f6a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# variants\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6faa5707",
   "metadata": {},
   "source": [
    "# Add Timeseries Data to Heatmap json File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8046f110",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_data={ }\n",
    "tdf={city:{}  for city in cities_list}\n",
    "tdf_mat={city:{}  for city in cities_list}\n",
    "\n",
    "# HACK do not upload 'undetermined' for now\n",
    "# variants = [v for v in variants if v != 'undetermined']\n",
    "# variants.append('undetermined')\n",
    "\n",
    "# this next line clips the plots from a given date\n",
    "only_start_from={\n",
    "    'Kanton Zürich':'2021-08-15', # start_date\n",
    "#     'B.1.1.529':'2021-10-05',\n",
    "}\n",
    "\n",
    "for var in tqdm(variants_upload, desc='Variants', position=0):\n",
    "    update_data[rename_variants.get(var, var)] = { }\n",
    "    for city in tqdm(cities_list_upload, desc=var, position=1, leave=False):\n",
    "        tdf[city][var] = agg3[city][var].apply(lambda x: {\"proportion\":np.clip(np.mean(x), 0., 1.),\n",
    "                                                          \"proportionLower\":np.clip(np.percentile(x, 5), 0., 1.),\n",
    "                                                          \"proportionUpper\":np.clip(np.percentile(x, 95), 0., 1.)},\n",
    "                                               axis=1, result_type ='expand')\n",
    "        if var in rename_variants:\n",
    "            tdf[city][var].rename(index={var:rename_variants[var]},inplace=True)\n",
    "        tdf[city][var] = tdf[city][var].reset_index()\n",
    "        tdf[city][var][\"date\"] = tdf[city][var][\"date\"].astype(\"str\")\n",
    "\n",
    "        update_data[rename_variants.get(var, var)][city] = {\n",
    "            #\"updateDate\": todaydate,\n",
    "            \"timeseriesSummary\": [dict(tdf[city][var].iloc[i,]) for i in range(tdf[city][var].shape[0]) if ((city not in only_start_from) or (tdf[city][var].loc[i,'date'] >= only_start_from[city])) and ((var not in only_start_from) or (tdf[city][var].loc[i,'date'] >= only_start_from[var]))],\n",
    "            \"mutationOccurrences\": (\n",
    "                [\n",
    "                    x for x in old_data[var][city][\"mutationOccurrences\"] if ((city not in only_start_from) or (x['date'] >= only_start_from[city])) and ((var not in only_start_from) or (x['date'] >= only_start_from[var]))\n",
    "                ] # old_update_data[var][city][\"mutationOccurrences\"], #[dict(tdf_mat[city][var].iloc[i,]) for i in range(tdf_mat[city][var].shape[0])]\n",
    "                if var != 'undetermined' else np.nan \n",
    "            ),\n",
    "        }\n",
    "\n",
    "import json\n",
    "with open(update_data_combined_file, 'w') as file:\n",
    "     file.write(json.dumps(update_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0f20a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update_data['B.1.617.2']['Altenrhein (SG)']['mutationOccurrences']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed3d4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_data['BA.2']['Altenrhein (SG)']['timeseriesSummary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ade2b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_data['undetermined']['Altenrhein (SG)'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71257fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2346154a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update_data['B.1.1.529']['Kanton Basel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951b93a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bio1",
   "language": "python",
   "name": "bio1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
