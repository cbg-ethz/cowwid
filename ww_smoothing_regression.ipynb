{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0eec56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "plotwidth=40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4dd207",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "from natsort import natsort_keygen\n",
    "import glob\n",
    "import yaml\n",
    "import numpy as np\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import math\n",
    "from natsort import natsort_keygen\n",
    "import glob\n",
    "import yaml\n",
    "import numpy as np\n",
    "import datetime\n",
    "import statsmodels.api as sm\n",
    "from tqdm.notebook import tqdm, trange\n",
    "from sklearn.utils import resample\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.optimize import nnls\n",
    "from scipy.optimize import minimize\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import glob\n",
    "import time\n",
    "import json\n",
    "import psycopg2\n",
    "import netrc\n",
    "import re\n",
    "import os\n",
    "from multiprocess import Pool\n",
    "\n",
    "lowess = sm.nonparametric.lowess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22fd8e7f",
   "metadata": {},
   "source": [
    "# Globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321278aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = '.'\n",
    "plotdir = 'plots'\n",
    "vpipe_working = 'working' # V-pipe's working directory\n",
    "\n",
    "\n",
    "tally_data = os.path.join(datadir, 'tallymut_line.tsv')\n",
    "plant_name_tsv = pd.read_csv('ww_plants.tsv')\n",
    "\n",
    "#for later\n",
    "# cooc_data = 'data/ww-cooc.csv'\n",
    "\n",
    "start_date = '2020-12-08'\n",
    "todaydate = datetime.date.today().strftime(\"%Y-%m-%d\")\n",
    "cities_list=['Altenrhein (SG)', 'Chur (GR)', 'Genève (GE)', 'Kanton Zürich', 'Laupen (BE)',\n",
    "       'Lausanne (VD)', 'Lugano (TI)', 'Zürich (ZH)']\n",
    "#cities_list=['Kanton Zürich','Kanton Zürich/Promega']\n",
    "variants_pangolin={'UK':'B.1.1.7','ZA':'B.1.351','BR':'P.1','C36':'C.36.3','IN1':'B.1.617.1','IN2':'B.1.617.2','IN3':'B.1.617.3'}\n",
    "variants = ['P.1', 'C.36.3', 'B.1.617.1', 'B.1.617.2', 'B.1.617.3', 'B.1.1.7', 'B.1.351']\n",
    "exclusive_list=['B.1.351','P.1'] # list of variants where we should apply filtering\n",
    "exclude_from=['B.1.1.7','B.1.351','P.1' ] #,'IN2'] #,'C36','IN1','IN2','IN3'] # filter against these variants\n",
    "max_pool = len(cities_list)\n",
    "\n",
    "# mutations type to be considered\n",
    "mut_types = ['mut', 'extra']\n",
    "# drop all shared and subset mutations\n",
    "to_drop = ['subset', 'shared']\n",
    "\n",
    "\n",
    "# Outputs\n",
    "plots_dir='deconv_plots'\n",
    "if not os.path.isdir(plots_dir):\n",
    "    try:\n",
    "        os.mkdir(plots_dir, mode=0o775)\n",
    "    except FileExistsError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92fbd79",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969605d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load tsv into dataframe\n",
    "df_tally = pd.read_csv(tally_data, sep='\\t')\n",
    "df_tally = df_tally.rename(columns=variants_pangolin)\n",
    "df_tally = df_tally.drop('EU', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2baf60d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = df_tally.copy()\n",
    "df_data.dropna(subset = [\"frac\", \"date\"], inplace=True)\n",
    "df_data['mutations'] = df_data['pos'].astype(str) + df_data['base']\n",
    "df_data = df_data[~(df_data['base'] == '-') & (df_data['date'] >= start_date) ]\n",
    "df_data = df_data[df_data.columns.difference(['pos', 'gene', 'base'], sort=False)]\n",
    "\n",
    "# drop other mutation type from df_data\n",
    "for v in variants:\n",
    "    df_data = df_data[~df_data[v].isin(to_drop)]\n",
    "\n",
    "df_data = df_data.reset_index(drop=True)\n",
    "\n",
    "mutations =  sorted(list(df_data['mutations'].unique()), key=natsort_keygen())\n",
    "# df_data[df_data['plantname'] == 'Altenrhein (SG)'].sort_values(by='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5371a1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data2 = df_data[df_data.columns.difference(['batch'], sort=False)]\n",
    "df_data2 = df_data2.replace(np.nan, 0)\n",
    "df_data2 = df_data2.replace(['extra', 'mut'], 1)\n",
    "df_data2 = df_data2[df_data2.columns.difference(['plantcode', 'cov', 'var'], sort=False)]\n",
    "df_data2 = df_data2.sort_values(by=['date', 'sample'])\n",
    "\n",
    "dates = sorted(set(df_data2['date']), key=natsort_keygen())\n",
    "# df_data2[(df_data2['plantname'] == 'Lugano (TI)') & (df_data2['date'] == '2021-07-20')]\n",
    "df_data2.insert(4, 'undetermined', 0)\n",
    "# sorted(df_data2['date'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b977e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Complement of matrix A (to add undetermined case)\n",
    "data = {'sample':df_data2['sample'], 'date':df_data2['date'], 'plantname':df_data2['plantname'],\n",
    "       'frac':1-df_data2['frac'], 'P.1':1-df_data2['P.1'], 'C.36.3':1-df_data2['C.36.3'], \n",
    "        'B.1.617.1':1-df_data2['B.1.617.1'], 'B.1.617.2':1-df_data2['B.1.617.2'], \n",
    "        'B.1.617.3':1-df_data2['B.1.617.3'],'B.1.1.7':1-df_data2['B.1.1.7'], \n",
    "        'B.1.351':1-df_data2['B.1.351'], 'mutations': '-' + df_data2['mutations'].astype(str)}\n",
    "\n",
    "df_data3 = pd.DataFrame(data)\n",
    "df_data3.insert(4, 'undetermined', 1)\n",
    "df_data3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b54cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data4 = pd.concat([df_data2, df_data3], sort=False)\n",
    "df_data4[df_data4['undetermined'] == 0]\n",
    "mutations =  sorted(list(df_data4['mutations'].unique()), key=natsort_keygen())\n",
    "df_data4[df_data4['B.1.617.2'] == 1]\n",
    "variants = ['undetermined', 'P.1', 'C.36.3', 'B.1.617.1', 'B.1.617.2', 'B.1.617.3', 'B.1.1.7', 'B.1.351']\n",
    "variants = sorted(variants, key=natsort_keygen())\n",
    "\n",
    "# sorted(df_data4[df_data4['plantname'] == cities_list[2]]['date'].unique())\n",
    "df_data4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdffa9ac",
   "metadata": {},
   "source": [
    "# Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690bface",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ineq_cons(x):\n",
    "    \"\"\"constrain all elements of x to be >= 0\"\"\"\n",
    "    return x\n",
    "\n",
    "def eq_cons(x):\n",
    "    \"\"\"constrain the sum of all rows to be equal to 1\"\"\"\n",
    "    return np.sum(x) - 1\n",
    "\n",
    "def fn(x, A, b):\n",
    "    return 0.5*np.linalg.norm(A.dot(x)-b)**2\n",
    "\n",
    "def cal_nnls_ridge2(X,y, lam, l=8):\n",
    "    p = X.shape[1]\n",
    "    Xext = np.vstack((X, lam * np.identity(X.shape[1])))\n",
    "\n",
    "    yext = np.hstack((y, np.zeros(p)))\n",
    "    coefs, _ = nnls(Xext, yext)\n",
    "\n",
    "    cons = [{'type': 'ineq', 'fun': ineq_cons},\n",
    "               {'type': 'eq', 'fun': eq_cons}]\n",
    "\n",
    "    #Call minimisation subject to these values\n",
    "    minout = minimize(fn, coefs, args=(Xext, yext), method='SLSQP',bounds=[(0., None) for i in range(l)]\n",
    "                      ,constraints=cons)\n",
    "\n",
    "    x = minout.x\n",
    "\n",
    "    return x    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a923ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regress_city(city): # globals: df_data2, df_data4, variants\n",
    "    current_ridge = []\n",
    "#     df_city1 = df_data2[(df_data2['plantname'] == city)]\n",
    "    df_city1 = df_data4[(df_data4['plantname'] == city)]\n",
    "    dates = sorted(set(df_city1['date']), key=natsort_keygen())\n",
    "\n",
    "    for n in trange(0,100, desc=city):\n",
    "        for d in dates:\n",
    "            muts = np.random.choice(mutations, len(mutations), replace=True)\n",
    "\n",
    "            df_city_date = df_city1[df_city1['date'] == d]\n",
    "            df_sampled = df_city_date[df_city_date['mutations'].map(lambda x: x in muts)]\n",
    "\n",
    "            if len(df_sampled) > 0:\n",
    "                df_ridge = df_sampled[df_sampled.columns.difference(['sample', 'date', 'plantname', 'mutations'], sort=False)]\n",
    "\n",
    "                char_vars = df_ridge[df_ridge.columns.difference(['sample', 'date','plantname',\n",
    "                                                                          'frac', 'mutations', 'date'])].columns.values\n",
    "\n",
    "                for value, variant in zip(cal_nnls_ridge2(np.array(df_ridge[variants]), np.array(df_ridge['frac']), 0.5,\n",
    "                                                              len(char_vars)), char_vars):\n",
    "                        current_ridge.append([variant, value, city, d, n])\n",
    "    return current_ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6c308a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_res=[]\n",
    "# city_ex = [cities_list[0]]#for testing\n",
    "\n",
    "#with Pool(max_pool) as p:\n",
    "#    global df_data2, df_data4, variants\n",
    "#    pool_res = list(\n",
    "#        tqdm(\n",
    "#            p.imap(regress_city,\n",
    "#                   cities_list),\n",
    "#            total=len(cities_list)\n",
    "#        )\n",
    "#    )\n",
    "#for res in pool_res:\n",
    "#    ridge_res += res\n",
    "\n",
    "for city in tqdm(cities_list, desc='Cities', position=0):\n",
    "    ridge_res += regress_city(city)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c57de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load regression coefs to dataframe\n",
    "df_ridge_res = pd.DataFrame(ridge_res)\n",
    "df_ridge_res = df_ridge_res.rename(columns={0: 'variant', 1: 'weight', 2: 'location', 3: 'date', 4: 'iter'})\n",
    "df_ridge_res['date'] = pd.to_datetime(df_ridge_res['date'])\n",
    "\n",
    "df_final = df_ridge_res.sort_values(by=['date','variant']).reset_index(drop=True)\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2695c618",
   "metadata": {},
   "source": [
    "# Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9baf42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Smoothing\n",
    "agg={}\n",
    "agg2={}\n",
    "agg3={}\n",
    "df_smooth1={}\n",
    "df_smooth2={}\n",
    "d_test={}\n",
    "#city_ex =[cities_list[0], cities_list[3]]\n",
    "for city in tqdm(cities_list, desc='Cities', position=0):\n",
    "    agg[city]={}\n",
    "    agg2[city]={}\n",
    "    agg3[city]={}\n",
    "    df_smooth1[city]={}\n",
    "    df_smooth2[city]={}\n",
    "    d_test[city]={}\n",
    "\n",
    "    for var in tqdm(variants, desc=city, position=1, leave=False):\n",
    "\n",
    "        df_smooth1[city][var] = df_final[(df_final['location'] == city) &\n",
    "                                         (df_final['variant'] == var)]\n",
    "\n",
    "        df_smooth1[city][var] = df_smooth1[city][var].groupby(['variant', 'location', 'date'])['weight'].apply(list)\n",
    "\n",
    "        df_smooth2[city][var] = df_smooth1[city][var].apply(pd.Series)\n",
    "\n",
    "        agg2[city][var] = df_smooth2[city][var].reset_index()\n",
    "        agg3[city][var] = (df_smooth2[city][var].apply(lambda x: lowess(x, np.arange(x.shape[0]).astype('float64'),\n",
    "                                                            xvals = np.arange(x.shape[0]).astype('float64'),\n",
    "                                                            frac= np.clip(20./df_smooth2[city][var].shape[0], 0, 2./3), it=0), 0))\n",
    "#                           ) if city != 'Kanton Zürich' else (\n",
    "#                             # For KLZH data\n",
    "#                            df_smooth2[city][var].apply(lambda x: x.rolling(window=2).mean(), 0)\n",
    "#                           )\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ee8115",
   "metadata": {},
   "source": [
    "# Prevalence Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3b814f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# show all variants separately\n",
    "sns.set_palette(\"dark\")\n",
    "variants = sorted(variants, key=natsort_keygen())\n",
    "for city in tqdm(cities_list, desc='Cities', position=0):\n",
    "\n",
    "#     print(city)\n",
    "#     fig = plt.figure()\n",
    "#     fig, ax = plt.subplots(nrows=1, figsize=(20, 10), sharex=False)\n",
    "#     ax = [ax]\n",
    "\n",
    "    for var in tqdm(variants, desc=city, position=1, leave=False):\n",
    "\n",
    "        fig = plt.figure()\n",
    "        fig, ax = plt.subplots(nrows=1, figsize=(20, 10), sharex=False)\n",
    "        ax = [ax]\n",
    "\n",
    "        # TODO be more clever with amplicons (for now we're just ignoring them)\n",
    "        xvals = sorted(list(set(agg2[city][var]['date'])))\n",
    "\n",
    "\n",
    "        sns.lineplot(x=xvals, y=np.clip(agg3[city][var].apply(np.nanmean, 1), 0., 1.),\n",
    "                     ax=ax[0], markers=True, label=var, linewidth=1)\n",
    "\n",
    "        ax[0].fill_between(xvals,\n",
    "                           np.clip(agg3[city][var].apply(lambda x: np.percentile(x, 5), 1).interpolate(), 0, 1),\n",
    "                           np.clip(agg3[city][var].apply(lambda x: np.percentile(x, 95), 1).interpolate(), 0, 1),\n",
    "                           alpha=.4)\n",
    "\n",
    "        ax[0].set_xlim((np.datetime64(start_date), np.datetime64(todaydate)))\n",
    "        ax[0].set_ylabel(f\"coeffs\")\n",
    "#         ax[0].legend(loc=\"upper left\")\n",
    "        ax[0].set_title(f\"{city}: smoothed regression curve\")\n",
    "#        plt.savefig(os.path.join(plots_dir, f'{city}_{var}.png')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a55135a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show all variants at the same time\n",
    "sns.set_palette(\"dark\")\n",
    "variants = sorted(variants, key=natsort_keygen())\n",
    "for city in tqdm(cities_list, desc='Cities', position=0):\n",
    "\n",
    "    fig = plt.figure()\n",
    "    fig, ax = plt.subplots(nrows=1, figsize=(20, 10), sharex=False)\n",
    "    ax = [ax]\n",
    "\n",
    "    for var in tqdm(variants, desc=city, position=1, leave=False):\n",
    "\n",
    "        # TODO be more clever with amplicons (for now we're just ignoring them)\n",
    "        xvals = sorted(list(set(agg2[city][var]['date'])))\n",
    "\n",
    "\n",
    "        sns.lineplot(x=xvals, y=np.clip(agg3[city][var].apply(np.nanmean, 1), 0., 1.),\n",
    "                     ax=ax[0], markers=True, label=var, linewidth=1)\n",
    "\n",
    "#         ax[0].fill_between(xvals,\n",
    "#                            np.clip(agg3[city][var].apply(lambda x: np.percentile(x, 5), 1).interpolate(), 0, 1),\n",
    "#                            np.clip(agg3[city][var].apply(lambda x: np.percentile(x, 95), 1).interpolate(), 0, 1),\n",
    "#                            alpha=.4)\n",
    "\n",
    "        ax[0].set_xlim((np.datetime64(start_date), np.datetime64(todaydate)))\n",
    "        ax[0].set_ylabel(f\"coeffs\")\n",
    "#         ax[0].legend(loc=\"upper left\")\n",
    "        ax[0].set_title(f\"{city}: smoothed regression curve\")\n",
    "    plt.savefig(os.path.join(plots_dir, f\"{city.replace('/','-')}.png\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a403c5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_data2[(df_data2['plantname'] == 'Lugano (TI)') & (df_data2['date'] == '2021-05-19')]\n",
    "df_data2[(df_data2['plantname'] == 'Kanton Zürich') & (df_data2['date'] == '2021-08-22')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7bee525",
   "metadata": {},
   "source": [
    "# Make data for covSPECTRUM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88690029",
   "metadata": {},
   "source": [
    "Actually, we are cheating, we are not really preparing the data for cov-spectrum, we are re-using the data that was created with the classical.\n",
    "\n",
    "You neet to have run [`ww_smoothing_cov.ipynb` all the way up to section New regression](ww_smoothing_cov.ipynb#New-regression) in order to generate the remaining upload data (heatmaps, etc.)\n",
    "\n",
    "**TODO** clean the heatmap generation code, and add it here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be6e276",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from IPython.display import JSON\n",
    "\n",
    "old_json='ww_update_data.json'\n",
    "print(\"reusing %s last modified: %s\" % (old_json, time.ctime(os.path.getmtime(old_json))))\n",
    "with open(old_json, 'r') as file:\n",
    "     old_update_data = json.load(file)\n",
    "#JSON(old_update_data) # only in Jupyter Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebc1d0e",
   "metadata": {},
   "source": [
    "## Replace the curve with the new regressions above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f589d5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_data={ }\n",
    "tdf={city:{}  for city in cities_list}\n",
    "tdf_mat={city:{}  for city in cities_list}\n",
    "\n",
    "# HACK do not upload 'undetermined' for now\n",
    "variants = [v for v in variants if v != 'undetermined']\n",
    "\n",
    "# this next line clips the plots from a given date\n",
    "only_start_from={'Kanton Zürich':'2021-08-15'} # start_date\n",
    "\n",
    "for var in tqdm(variants, desc='Variants', position=0):\n",
    "    update_data[var] = { }\n",
    "    for city in tqdm(cities_list, desc=var, position=1, leave=False):\n",
    "        tdf[city][var] = agg3[city][var].apply(lambda x: {\"proportion\":np.clip(np.mean(x), 0., 1.),\n",
    "                                                          \"proportionLower\":np.clip(np.percentile(x, 5), 0., 1.),\n",
    "                                                          \"proportionUpper\":np.clip(np.percentile(x, 95), 0., 1.)},\n",
    "                                               axis=1, result_type ='expand')\n",
    "        tdf[city][var] = tdf[city][var].reset_index()\n",
    "        tdf[city][var][\"date\"] = tdf[city][var][\"date\"].astype(\"str\")\n",
    "\n",
    "        #tdf_mat[city][var] = m_df[city][var].T.melt(ignore_index=False, var_name=\"nucMutation\", value_name=\"proportion\").reset_index()\n",
    "        #tdf_mat[city][var][\"date\"] = tdf_mat[city][var][\"date\"].astype(\"str\")\n",
    "        # # drawing box decorations:\n",
    "        # # ┌22917G\n",
    "        # # ├22995A\n",
    "        # # └Amplicon 76\n",
    "        #if var in amplicons:\n",
    "        #    # mutations\n",
    "        #    for amp,muts in amplicons[var].items():\n",
    "        #        box = '┌'\n",
    "        #        for m in muts:\n",
    "        #            tdf_mat[city][var].loc[tdf_mat[city][var][\"nucMutation\"]==m,\"nucMutation\"]=f\"{box}{m}\"\n",
    "        #            box = '├'\n",
    "        #    for a in amp_col[var]:\n",
    "        #            tdf_mat[city][var].loc[tdf_mat[city][var][\"nucMutation\"]==a,\"nucMutation\"]=f\"└{a}\"\n",
    "\n",
    "        update_data[var][city] = {\n",
    "            #\"updateDate\": todaydate,\n",
    "            \"timeseriesSummary\": [dict(tdf[city][var].iloc[i,]) for i in range(tdf[city][var].shape[0]) if (city not in only_start_from) or (tdf[city][var].loc[i,'date'] >= only_start_from[city])],\n",
    "            \"mutationOccurrences\": [ x for x in old_update_data[var][city][\"mutationOccurrences\"] if (city not in only_start_from) or (x['date'] >= only_start_from[city])], # old_update_data[var][city][\"mutationOccurrences\"], #[dict(tdf_mat[city][var].iloc[i,]) for i in range(tdf_mat[city][var].shape[0])],\n",
    "        }\n",
    "\n",
    "import json\n",
    "with open('ww_update_data_regression.json', 'w') as file:\n",
    "     file.write(json.dumps(update_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e6d456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the generated curve data for one example\n",
    "tdf['Zürich (ZH)']['B.1.1.7']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d243a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the uploaded curve data for one example\n",
    "# NOTE this is clipped using only_start_from\n",
    "#update_data['B.1.1.7']['Zürich (ZH)'][\"timeseriesSummary\"]\n",
    "update_data['B.1.1.7']['Kanton Zürich'][\"timeseriesSummary\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335a4e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the (copy-pasted) heatmap data for one example\n",
    "# NOTE this is clipped using only_start_from\n",
    "#update_data['B.1.1.7']['Zürich (ZH)'][\"mutationOccurrences\"]\n",
    "update_data['B.1.1.7']['Kanton Zürich'][\"mutationOccurrences\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ca4e54",
   "metadata": {},
   "source": [
    "## Upload to Cov-Spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5e5b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbhost='id-hdb-psgr-cp61.ethz.ch'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d995fb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load from netrc\n",
    "dbuser,dbpass=netrc.netrc().authenticators(dbhost)[0::2]\n",
    "\n",
    "# alternative: input box\n",
    "#dbuser = input(f\"Enter username for database {dbhost}:\\n\")\n",
    "#dbpass = input(f\"Enter password for user {dbuser}:\\n\")\n",
    "\n",
    "# alternative: enviro\n",
    "#dbuser = os.environ['DB_USERNAME'],\n",
    "#dbpass = os.environ['DB_PASSWORD'],\n",
    "\n",
    "dbuser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525890d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbconn = psycopg2.connect(\n",
    "    host=dbhost,\n",
    "    database='sars_cov_2',\n",
    "    user=dbuser,\n",
    "    password=dbpass,\n",
    "    port='5432'\n",
    ")\n",
    "dbconn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eceb60b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur = dbconn.cursor()\n",
    "cur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93d6a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pango in variants:\n",
    "    for city in cities_list:\n",
    "        cur.execute(\"\"\"\n",
    "        DO $$\n",
    "        BEGIN\n",
    "         IF EXISTS (SELECT ww.data FROM public.spectrum_waste_water_result AS ww WHERE ww.variant_name=%(var)s AND ww.location=%(city)s) THEN\n",
    "          UPDATE public.spectrum_waste_water_result AS ww SET data=%(data)s WHERE ww.variant_name=%(var)s AND ww.location=%(city)s;\n",
    "         ELSE\n",
    "          INSERT INTO public.spectrum_waste_water_result (variant_name, location, data)\n",
    "          VALUES(%(var)s, %(city)s, %(data)s);\n",
    "         END IF;\n",
    "        END\n",
    "        $$\n",
    "        \"\"\", {'data': json.dumps(update_data[pango][city]).replace('NaN','null'), 'var': pango, 'city': city})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06793786",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Abort DB update !\n",
    "dbconn.rollback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49529f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save to DB !\n",
    "dbconn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570131e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.close()\n",
    "dbconn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e15cc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bio1",
   "language": "python",
   "name": "bio1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
