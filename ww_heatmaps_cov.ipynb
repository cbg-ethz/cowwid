{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48afcc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "plotwidth=40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c40bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from natsort import natsort_keygen\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import scipy as sp\n",
    "\n",
    "import os\n",
    "import json\n",
    "import datetime\n",
    "import psycopg2\n",
    "import netrc\n",
    "import re\n",
    "import yaml\n",
    "from tqdm.notebook import tqdm, trange\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "tqdm_notebook.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aedb2af9",
   "metadata": {},
   "source": [
    "# Globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c964b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = '.'\n",
    "plotdir = 'plots'\n",
    "vpipe_working = 'working' # V-pipe's working directory\n",
    "\n",
    "# Input\n",
    "tally_mut = os.path.join(datadir, 'tallymut_line.tsv')\n",
    "cooc_table = {\n",
    "    'v3':os.path.join(vpipe_working, 'ww-cooc.v3.csv'),\n",
    "    'v4':os.path.join(vpipe_working, 'ww-cooc.v4.csv'),\n",
    "}\n",
    "amplicons_yaml = {\n",
    "    'v3':os.path.join(vpipe_working, 'amplicons.v3.yaml'),\n",
    "    'v4':os.path.join(vpipe_working, 'amplicons.v4.yaml'),\n",
    "}\n",
    "\n",
    "# Select\n",
    "start_date = '2020-12-08'\n",
    "start_date_klzh = '2021-08-15'\n",
    "todaydate = datetime.date.today().strftime(\"%Y-%m-%d\")\n",
    "cities_list=['Altenrhein (SG)', 'Chur (GR)', 'Genève (GE)', 'Laupen (BE)',\n",
    "       'Lausanne (VD)', 'Lugano (TI)', 'Zürich (ZH)', 'Kanton Zürich', 'Basel (catchment area ARA Basel)']\n",
    "# variants that will be displayed here AND uploaded:\n",
    "variants_list_upload=['al', 'be', 'ga', 'de', 'ka', 'om1','om2',] # C36, AY42, mu, B16173, d614g\n",
    "# extra variants that will be ONLY display here, but NOT uploaded (typically for variant not present yet)\n",
    "variants_list=variants_list_upload+['BA1','BA2',]\n",
    "variants_pangolin={'al':'B.1.1.7','be':'B.1.351','ga':'P.1','C36':'C.36.3','ka':'B.1.617.1','de':'B.1.617.2','AY42':'AY.4.2','B16173':'B.1.617.3','om1':'BA.1','om2':'BA.2','BA1':'custom-BA.1','BA2':'custom-BA.2'}\n",
    "exclusive_list=['be','ga'] # list of variants where we should apply filtering\n",
    "exclude_from=['al','be','ga' ] #,'IN2'] #,'C36','IN1','IN2','IN3'] # filter against these variants\n",
    "# currently, heatmaps can only display amplicons from 1 single protocol\n",
    "amplicons_proto = { v:'v4' for v in ['om1','om2','BA1','BA2'] }\n",
    "amplicons_proto.update({ v:'v3' for v in variants_list if v not in amplicons_proto.keys() })\n",
    "display(amplicons_proto)\n",
    "\n",
    "# Output\n",
    "update_data_file = os.path.join(datadir, 'ww_update_data_heatmap.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf5dc0b",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de57d893",
   "metadata": {},
   "outputs": [],
   "source": [
    "amplicons = {}\n",
    "# process amplicons definition for each proto\n",
    "for (pro,fname) in amplicons_yaml.items():\n",
    "    with open(fname, 'rt') as yf:\n",
    "        amp_str = yaml.safe_load(yf)\n",
    "    # process each enty\n",
    "    for (aname,adata) in amp_str.items():\n",
    "        # parse: 88_BA1_BA2\n",
    "        pn=aname.split(\"_\")\n",
    "        num=int(pn[0]) # number\n",
    "        for av in pn[1:]: # variants\n",
    "            # only process if we're supposed to use that version for that variant:\n",
    "            if amplicons_proto.get(av, None) != pro:\n",
    "                continue\n",
    "            # only process non-indels (because indels aren't on heatmap)\n",
    "            muts = [ f\"{p3}{m3}\" for p3,m3 in sorted([(p2,m2) for p,m in adata[4].items() for p2,m2 in zip(range(p,p+len(m)),m) ]) ] #if m3[0] not in \"-+\" ]\n",
    "            if len(muts)==0:\n",
    "                continue\n",
    "            # add to dict\n",
    "            add = { num: muts}\n",
    "            print(f\"{pro} {av} {num} {','.join(muts)}/{len(muts)}\")\n",
    "            if av not in amplicons:\n",
    "                amplicons[av] = add\n",
    "            else:\n",
    "                amplicons[av].update(add)\n",
    "amplicons={ v:dict(sorted(amps.items()))  for v,amps in amplicons.items() }\n",
    "display(amplicons)\n",
    "#    'IN1': { 76: ['22917G', '23012C'], },\n",
    "#    'IN3': { 76: ['22917G', '23012C'], },\n",
    "#    'IN2': { 76: ['22917G', '22995A'],\n",
    "#             91: ['27638C', '27752T'], },\n",
    "#    'BR':  { 71: ['21621A', '21638T'],  # ,'21614T'], # common mutations are removed from the plot\n",
    "#             # 95: ['28877T',  '28878C'], # not part of the signature mutations\n",
    "#           },\n",
    "#    'AY42':{ 73: ['21995C','22227T'], },\n",
    "#\n",
    "#    'om':  { 75: ['22578A','22673C','22674T','22679C','22813T'],\n",
    "# v4 \n",
    "#             75_om[22578A,22673CTC,22679C]\n",
    "#             76: ['22882G','22898A','22992A','23013C','23040G','23048A','23055G'],\n",
    "#             78: ['23525T','23599G'],\n",
    "#             88: ['26577G','26709A'],\n",
    "#           },"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb5508b",
   "metadata": {},
   "source": [
    "## Load WWTP Sequencing Data\n",
    "\n",
    "#### Tally of mutations in samples\n",
    "\n",
    "This loads the TSV file generated by the [mut-table.ipynb](mut-table.ipynb) notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa7e5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(tally_mut, sep='\\t', parse_dates=['date'])\n",
    "\n",
    "df['mutation'] = df['pos'].astype(str) + df['base']\n",
    "df#.head()\n",
    "sorted(df['date'].unique())\n",
    "df[df['date'] == '2021-12-27']\n",
    "sorted(df[df['plantname'] == 'Basel (catchment area ARA Basel)']['date'].unique())\n",
    "df[df['plantname'] == 'Basel (catchment area ARA Basel)']['batch'].unique()\n",
    "df[df['batch'] == '20220110_HKLFGDRXY']['plantname'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9314c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove problematic mutations (from mutation influence diagnostic) (hard-coded now)\n",
    "\n",
    "df = df[~(df['mutation'].isin([\"28461G\", \"11201G\", \"26801C\"]))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423e0b3d",
   "metadata": {},
   "source": [
    "### Cooccurrences by cojac\n",
    "\n",
    "This loads the CSV generated by the `ww.bsub` LSF job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc896c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cooc_raw = { pro:pd.read_csv(fname, sep=',') for (pro,fname) in cooc_table.items() }\n",
    "#, index_col=['sample','batch'])\n",
    "\n",
    "#df['mutation'] = df['pos'].astype(str) + df['base']\n",
    "\n",
    "df_cooc_raw['v3'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6757a0",
   "metadata": {},
   "source": [
    "### Handle duplicates\n",
    "\n",
    "The code in the notebook will have trouble if some indexes are duplicated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3bfc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look for duplicated samples with suffixes\n",
    "df[(~df['plantname'].isna()) & (df['date'] >= start_date) & (df['base'] != '-') & df.duplicated(subset=['plantname','date','batch','mutation'], keep=False)]#.groupby('batch').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd8a509",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HACK workaround for a duplicated sample\n",
    "df['batch'].loc[df['sample']=='A1_05_2021_05_19_CATTCGGA-TTTCCATC']='20210604_JN8TR_CATTCGGA-TTTCCATC'\n",
    "for pro in df_cooc_raw.keys():\n",
    "    df_cooc_raw[pro]['batch'].loc[df_cooc_raw[pro]['sample']=='A1_05_2021_05_19_CATTCGGA-TTTCCATC']='20210604_JN8TR_CATTCGGA-TTTCCATC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b22b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HACK workaround for a duplicated sample\n",
    "df['batch'].loc[df.duplicated(subset=['plantname','date','batch','mutation'], keep=False) & df['sample'].str.contains('_P$')]='Promega'\n",
    "for pro in df_cooc_raw.keys():\n",
    "    df_cooc_raw[pro]['batch'].loc[df_cooc_raw[pro]['sample'].str.contains('_P$')]='Promega'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977e5142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look for duplicated samples with suffixes\n",
    "df[(~df['plantname'].isna()) & (df['date'] >= start_date) & (df['base'] != '-') & df.duplicated(subset=['plantname','date','batch','mutation'], keep=False)].groupby('batch').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f45b5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cooc_raw['v3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc016be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plantcode and date from mut_table to cooc\n",
    "\n",
    "df_map=df[['sample','batch','plantname','date']].drop_duplicates(ignore_index=True).set_index(['sample','batch'])\n",
    "df_cooc={ pro:df_cooc_raw[pro].merge(df_map[['plantname','date']], how='left', on=['sample','batch'], copy=False, validate='many_to_one').set_index(['plantname','date','batch']) for pro in df_cooc_raw.keys() }\n",
    "df_cooc['v3']#.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c799a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (pro,pro_df) in df_cooc.items():\n",
    "    pro_df.to_csv(f\"df_cooc.{pro}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffbd1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutfilter(var, exclusive=False):\n",
    "    # if exclusive is set on true, it will filter only those mutation which are variant specific and DO NOT show up in other variants\n",
    "    # e.g.: used to exclude 23063T (V501Y) as all variant have it\n",
    "    return (df[exclude_from].fillna(0) == ['mut' if v==var else 0 for v in exclude_from]).all(axis=1) if exclusive else (df[var] == \"mut\")\n",
    "mutfilter('al', exclusive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320b604a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wide = {}\n",
    "amp_col = {}\n",
    "rx_num = re.compile(r\"^(\\d+)\")\n",
    "for var in tqdm(variants_list):\n",
    "    df_wide[var] = (\n",
    "        # for the remaining mutations\n",
    "        df[(~df['plantname'].isna()) & (df['date'] >= start_date) & (df['base'] != '-') & (mutfilter(var, exclusive=(var in exclusive_list)))]\n",
    "         .pivot(index=['plantname', 'date', 'batch'], columns=['mutation'], values='frac')\n",
    "         .sort_index(axis=1, key=natsort_keygen())\n",
    "    )\n",
    "    # add amplicons\n",
    "    if var in amplicons and var in amplicons_proto:\n",
    "        amp_col[var] = []\n",
    "        for amp,muts in amplicons[var].items():\n",
    "            # transfer this column from the coocurence table...\n",
    "            aname =  f\"Amp {amp}\"\n",
    "            amplicon_table = df_cooc[amplicons_proto[var]].loc[(df_cooc[amplicons_proto[var]]['amplicon'] == amp) & (df_cooc[amplicons_proto[var]][var]==1), ['frac']]\n",
    "            amp_col[var] += [ aname ]\n",
    "            # (filled with NA on dates for which we don't have coocurence, and subset to target indices)\n",
    "            missing_cooc = df_wide[var].index.difference(amplicon_table.index)\n",
    "            na_filled_col = pd.concat([amplicon_table, pd.DataFrame(index=missing_cooc, columns=amplicon_table.columns).fillna(np.nan)])\n",
    "            # ...into that position\n",
    "            if muts[-1] in df_wide[var].columns:\n",
    "                cooccol=1+df_wide[var].columns.get_loc(muts[-1])\n",
    "            else:\n",
    "                # [inefficient] roughly the same idea as get_loc(method='fill'), but our index isn't monotonic\n",
    "                cooccol=0\n",
    "                srch=int(rx_num.search(muts[-1]).group()) # to number\n",
    "                for idx in df_wide[var].columns:\n",
    "                    cooccol+=1\n",
    "                    inum=rx_num.search(idx) # begins with numbe?\n",
    "                    if inum is not None and int(inum.group()) > srch: #numerical comparison\n",
    "                        break\n",
    "            df_wide[var].insert(loc=cooccol, column=aname, value=na_filled_col.loc[df_wide[var].index], allow_duplicates=False)\n",
    "\n",
    "df_wide['ga'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3e87c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wide['om1'].loc['Basel (catchment area ARA Basel)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9df92e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wide_cov = (\n",
    "    df[(~df['plantname'].isna()) & (df['date'] >= '2020-12-08') & (df['base'] != '-') & (df['al'] == \"mut\")]\n",
    "    .pivot(index=['plantname', 'date', 'batch'], columns=['mutation'], values='cov')\n",
    "    .sort_index(axis=1, key=natsort_keygen())\n",
    ")\n",
    "\n",
    "df_wide_counts = (\n",
    "    df[(~df['plantname'].isna()) & (df['date'] >= '2020-12-08') & (df['base'] != '-') & (df['al'] == \"mut\")]\n",
    "    .pivot(index=['plantname', 'date', 'batch'], columns=['mutation'], values='var')\n",
    "    .sort_index(axis=1, key=natsort_keygen())\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c80008",
   "metadata": {},
   "source": [
    "# Heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93671a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "for city in tqdm(cities_list, desc='Cities', position=0): # ['Basel (catchment area ARA Basel)']:#\n",
    "    for var in tqdm(variants_list, desc='Variants', position=1):\n",
    "        tmp=df_wide[var].loc[city]\n",
    "\n",
    "        # drawing box decorations:\n",
    "        #\n",
    "        #      22917G╮        27972T╮\n",
    "        #      22995A┤        28048T┤\n",
    "        # Amplicon 76╯        28111G┪\n",
    "        #                Amplicon 92┩\n",
    "        #      22679C┓        28280C┤\n",
    "        #      22688G┨        28281T┤\n",
    "        #      22775A┨        28282A┤\n",
    "        # Amplicon 75┩   Amplicon 93╯\n",
    "        #      22786C┤\n",
    "        # Amplicon 76╯   Amplicon 73-\n",
    "\n",
    "        if var in amplicons:\n",
    "            rmap={}\n",
    "            endbox={}\n",
    "            l_amp = 'x'\n",
    "\n",
    "            # mutations\n",
    "            for amp,muts in amplicons[var].items():\n",
    "                box = '╮' #'┐'\n",
    "                dblbox = '┪'\n",
    "                for m in muts:\n",
    "                    if m in tmp.columns:\n",
    "                        if m not in rmap:\n",
    "                            rmap[m]=f\"{m}{box}\"\n",
    "                        else:\n",
    "                            rmap[m]=f\"{m}{'┓' if rmap[m][-1] == '╮' else dblbox}\"\n",
    "                            dblbox = '┨'\n",
    "                            endbox[l_amp] = \"┩\"\n",
    "                        box = '┤'\n",
    "                        endbox[f\"Amp {amp}\"] = '╯' # \"┘\"\n",
    "                l_amp=f\"Amp {amp}\"\n",
    "            #display(endbox)\n",
    "\n",
    "            # amplicons\n",
    "            for a in amp_col[var]:\n",
    "                rmap[a]=f\"{a}{endbox.get(a,'-')}\"\n",
    "            #print(rmap)\n",
    "            tmp.rename(columns=rmap,inplace=True)\n",
    "\n",
    "        plt.figure(figsize=(plotwidth,7)) # 17\n",
    "        trns=tmp.T\n",
    "        sns.heatmap(\n",
    "            data=trns.fillna(np.nan), #applymap(lambda x: np.nan if pd.isna(x) else x),\n",
    "            annot=trns,\n",
    "            fmt='.1g',\n",
    "            square=False, cbar=False,\n",
    "            cmap=sns.color_palette(\"viridis\", as_cmap=True)\n",
    "        ).set_title(f\"{city} - {variants_pangolin[var]}\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57936cd",
   "metadata": {},
   "source": [
    "# Prepare Heatmap Data for covSPECTRUM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697405e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "with warnings.catch_warnings(record=True) as w:\n",
    "    r_df={}\n",
    "    for city in tqdm(cities_list, desc='Cities', position=0):\n",
    "        r_df[city]={}\n",
    "        for var in tqdm(variants_list, desc='Variants', position=1, leave=False):\n",
    "            r_df[city][var] = df_wide[var].loc[city].dropna(axis=1, how='all').T  # .loc[28111:28111]\n",
    "\n",
    "m_df={}\n",
    "# import matplotlib.gridspec as gridspec\n",
    "for city in tqdm(cities_list, desc='Cities', position=0):\n",
    "    m_df[city]={}\n",
    "    for var in tqdm(variants_list_upload, desc='Variants', position=1, leave=False):\n",
    "        m_df[city][var] = r_df[city][var].T.groupby(\"date\").agg(\"mean\").asfreq('D').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da7183d",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8848d234",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_df['Altenrhein (SG)'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0677d7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_df['Altenrhein (SG)']['al']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8905839",
   "metadata": {},
   "source": [
    "# Make data for covSPECTRUM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded6e0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_data={ }\n",
    "tdf={city:{}  for city in cities_list}\n",
    "tdf_mat={city:{}  for city in cities_list}\n",
    "\n",
    "# add 'undetermined' variant\n",
    "update_data['undetermined'] = {\n",
    "    # undertermined don't have their own proper heatmap (they are definted by signature missing for all other variant)\n",
    "    city: {\"mutationOccurrences\": None} for city in cities_list\n",
    "}\n",
    "\n",
    "# process heatmaps normally for all other variants.\n",
    "for var in tqdm(variants_list_upload, desc='Variants', position=0):\n",
    "    update_data[variants_pangolin[var]] = { }\n",
    "    for city in tqdm(cities_list, desc='Cities', position=1, leave=False): #['Basel (catchment area ARA Basel)']:#\n",
    "\n",
    "#         tdf[city][var][\"date\"] = tdf[city][var][\"date\"].astype(\"str\")\n",
    "\n",
    "        tdf_mat[city][var] = m_df[city][var].T.melt(ignore_index=False, var_name=\"nucMutation\", value_name=\"proportion\").reset_index()\n",
    "        tdf_mat[city][var][\"date\"] = tdf_mat[city][var][\"date\"].astype(\"str\")\n",
    "        #print(tdf_mat[city][var][\"nucMutation\"])\n",
    "        if var in amplicons:\n",
    "            ## drawing box decorations:\n",
    "            ## ┌22917G\n",
    "            ## ├22995A\n",
    "            ## └Amplicon 76\n",
    "            ## mutations\n",
    "            #for amp,muts in amplicons[var].items():\n",
    "            #    box = '╭' #'┌'\n",
    "            #    endbox = '-'\n",
    "            #    for m in muts:\n",
    "            #        tdf_mat[city][var].loc[tdf_mat[city][var][\"nucMutation\"]==m,\"nucMutation\"]=f\"{box}{m}\"\n",
    "            #        box = '├'\n",
    "            #        endbox = '╰'#'└'\n",
    "            ## amplicons\n",
    "            #for a in amp_col[var]:\n",
    "            #        tdf_mat[city][var].loc[tdf_mat[city][var][\"nucMutation\"]==a,\"nucMutation\"]=f\"{endbox}{a}\"\n",
    "\n",
    "            # drawing box decorations:\n",
    "            #\n",
    "            # ╭22917G        ╭27972T\n",
    "            # ├22995A        ├28048T\n",
    "            # ╰Amplicon 76   ┢28111G\n",
    "            #                ┡Amplicon 92\n",
    "            # ┏22679C        ├28280C\n",
    "            # ┠22688G        ├28281T\n",
    "            # ┠22775A        ├28282A\n",
    "            # ┡Amplicon 75   ╰Amplicon 93\n",
    "            # ├22786C\n",
    "            # ╰Amplicon 76  ~Amplicon 73~\n",
    "\n",
    "            rmap={}\n",
    "            endbox={}\n",
    "            l_amp='x'\n",
    "            # mutations\n",
    "            for amp,muts in amplicons[var].items():\n",
    "                box = '╭' #'┌'\n",
    "                dblbox= '┢'\n",
    "                for m in muts:\n",
    "                    if m in m_df[city][var].index: #tdf_mat[city][var][\"nucMutation\"]:\n",
    "                        if m not in rmap:\n",
    "                            rmap[m]=f\"{box}{m}\"\n",
    "                        else:\n",
    "                            rmap[m]=f\"{'┏' if rmap[m][0] == '╭' else dblbox}{m}\"\n",
    "                            dblbox='┠'\n",
    "                            endbox[l_amp] = \"┡\"\n",
    "                        box = '├'\n",
    "                        endbox[f\"Amp {amp}\"] = '╰'#'└'\n",
    "                l_amp=f\"Amp {amp}\"\n",
    "            #print(endbox)\n",
    "\n",
    "            # amplicons\n",
    "            for a in amp_col[var]:\n",
    "                if a in endbox:\n",
    "                    rmap[a]=f\"{endbox[a]}{a}\"\n",
    "                else:\n",
    "                    # remove\n",
    "                    tdf_mat[city][var].drop(tdf_mat[city][var].loc[tdf_mat[city][var][\"nucMutation\"]==a].index)\n",
    "            \n",
    "            # wite modifications\n",
    "            #print(rmap)\n",
    "            for orig,art in rmap.items():\n",
    "                tdf_mat[city][var].loc[tdf_mat[city][var][\"nucMutation\"]==orig,\"nucMutation\"]=art\n",
    "                  \n",
    "          \n",
    "        update_data[variants_pangolin[var]][city] = {\n",
    "            #\"updateDate\": todaydate,\n",
    "#             \"timeseriesSummary\": [dict(tdf[city][var].iloc[i,]) for i in range(tdf[city][var].shape[0])],\n",
    "            \"mutationOccurrences\": [dict(tdf_mat[city][var].iloc[i,]) for i in range(tdf_mat[city][var].shape[0])]\n",
    "        }\n",
    "\n",
    "import json\n",
    "with open(update_data_file, 'w') as file:\n",
    "     file.write(json.dumps(update_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed811338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tdf_mat['Altenrhein (SG)'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c29d5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_data['undetermined']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22832b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_data[variants_pangolin['om']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f39abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "(0.5+len(df_wide['om'].loc['Zürich (ZH)'].columns)/5.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c27a0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "(0.5+len(df_wide['ga'].loc['Zürich (ZH)'].columns)/5.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f7b9b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bio1",
   "language": "python",
   "name": "bio1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
