{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66db2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "plotwidth=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84cbfad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from WwDec.main import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf5e25c",
   "metadata": {},
   "source": [
    "# Globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d4d3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source of inspiration from covariatns, see:\n",
    "# https://github.com/hodcroftlab/covariants/blob/master/web/data/clusters.json\n",
    "#\n",
    "# Keep in sync with covspectrum, see:\n",
    "# https://github.com/cevo-public/cov-spectrum-website/blob/develop/src/models/wasteWater/constants.ts\n",
    "color_map = {\n",
    "  'B.1.1.7': '#D16666',\n",
    "  'B.1.351': '#FF6665',\n",
    "  'P.1': '#FFB3B3',\n",
    "  'B.1.617.1': '#66C265',\n",
    "  'B.1.617.2': '#66A366',\n",
    "  'BA.1': '#A366A3',\n",
    "  'BA.2': '#cfafcf',\n",
    "  'BA.4': '#8a66ff',\n",
    "  'BA.5': '#585eff',\n",
    "  'BA.2.12.1': '#0400e0',\n",
    "  'BA.2.75': '#008fe0',\n",
    "  'BA.2.75.2': '#208fe0', # improv\n",
    "  'BQ.1.1': '#8fe000', # improv\n",
    "  'undetermined': '#969696',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4277738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overwrite globals set by WwDec.main:\n",
    "# temporary, globals\n",
    "tally_data = \"./work-vp-test/variants/tallymut.tsv.zst\" # zst needs python's Zstandard # \"./tallymut_line.tsv\"\n",
    "out_dir = (\n",
    "    \"./out\"\n",
    ")\n",
    "variants_list = [\n",
    "    \"B.1.1.7\",\n",
    "    \"B.1.351\",\n",
    "    \"P.1\",\n",
    "    \"B.1.617.2\",\n",
    "    \"B.1.617.1\",\n",
    "    \"BA.1\",\n",
    "    \"BA.2\",\n",
    "    \"BA.4\",\n",
    "    \"BA.5\",\n",
    "    \"BA.2.75\",\n",
    "    #\"BA.2.75.2\",\n",
    "    \"BQ.1.1\",\n",
    "]\n",
    "variants_pangolin = {\n",
    "    \"al\": \"B.1.1.7\",\n",
    "    \"be\": \"B.1.351\",\n",
    "    \"ga\": \"P.1\",\n",
    "    \"C36\": \"C.36.3\",\n",
    "    \"ka\": \"B.1.617.1\",\n",
    "    \"de\": \"B.1.617.2\",\n",
    "    \"AY42\": \"AY.4.2\",\n",
    "    \"B16173\": \"B.1.617.3\",\n",
    "    \"om1\": \"BA.1\",\n",
    "    \"om2\": \"BA.2\",\n",
    "    \"om4\": \"BA.4\",\n",
    "    \"om5\": \"BA.5\",\n",
    "    \"om275\": \"BA.2.75\",\n",
    "    \"om2752\": \"BA.2.75.2\",\n",
    "    \"ombq11\": \"BQ.1.1\",\n",
    "    \"om2121\": \"BA.2.12.1\",\n",
    "}\n",
    "variants_not_reported = [\n",
    "    \"BA.2.75.2\",\n",
    "    \"BA.2.12.1\",\n",
    "    \"phe-BA.1\",\n",
    "    \"phe-BA.2\",\n",
    "    \"C.36.3\",\n",
    "    \"B.1.617.3\",\n",
    "    \"AY.4.2\",\n",
    "    \"mu\",\n",
    "    \"d614g\",\n",
    "]\n",
    "start_date = \"2020-12-08\"\n",
    "to_drop = [\"subset\", \"shared\"]\n",
    "cities_list = [\n",
    "    \"Lugano (TI)\",\n",
    "    \"Zürich (ZH)\",\n",
    "    \"Chur (GR)\",\n",
    "    \"Altenrhein (SG)\",\n",
    "    \"Laupen (BE)\",\n",
    "    \"Genève (GE)\",\n",
    "    \"Basel (catchment area ARA Basel)\",\n",
    "#    \"Lausanne (VD)\",\n",
    "#    \"Kanton Zürich\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f29960",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# local settings for this notebook\n",
    "rename_variants = { } # 'omi-BA.2': 'BA.2'}\n",
    "datadir = '.'\n",
    "\n",
    "# Outputs\n",
    "plots_dir='deconv_plots'\n",
    "if not os.path.isdir(plots_dir):\n",
    "    try:\n",
    "        os.mkdir(plots_dir, mode=0o775)\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "update_data_lin_file = os.path.join(datadir, 'ww_update_data_smooth_kernel_lin.json')\n",
    "update_data_rob_file = os.path.join(datadir, 'ww_update_data_smooth_kernel_rob.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8868cd",
   "metadata": {},
   "source": [
    "# Load and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73776b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tally = pd.read_csv(tally_data, sep=\"\\t\")#.drop(columns=['proto'])\n",
    "df_tally.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612dc75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(df_tally.columns) - set(variants_pangolin.keys()) - {'base','batch','cov','date','frac','gene','plantcode','plantname','pos','proto','sample','var'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af36e51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "preproc = DataPreprocesser(df_tally)\n",
    "preproc = preproc.general_preprocess(\n",
    "    variants_list=variants_list,\n",
    "    variants_pangolin=variants_pangolin,\n",
    "    variants_not_reported=variants_not_reported,\n",
    "    to_drop=[\"subset\"],\n",
    "    start_date=start_date,\n",
    "    remove_deletions=True,\n",
    ")\n",
    "t_df_tally = preproc.df_tally\n",
    "# split into v41 and not v41, filter mutations and join\n",
    "df_tally_v41 = preproc.df_tally[preproc.df_tally.proto == 'v41'] \n",
    "print(df_tally_v41.shape)\n",
    "preproc.df_tally = preproc.df_tally[preproc.df_tally.proto != 'v41'] \n",
    "preproc = preproc.filter_mutations()\n",
    "print(preproc.df_tally.shape)\n",
    "\n",
    "preproc.df_tally = pd.concat([preproc.df_tally,df_tally_v41])\n",
    "print(preproc.df_tally.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e4ffa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in cities_list: #['Lugano (TI)', 'Zürich (ZH)', 'Chur (GR)', 'Altenrhein (SG)', 'Laupen (BE)', 'Genève (GE)']:\n",
    "    print(df_tally[(df_tally.location==name) & (df_tally.proto==\"v41\")].date.max(), name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3690b89",
   "metadata": {},
   "source": [
    "# Look at design of mutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a694a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "des_matrix = preproc.df_tally[variants_list + [\"undetermined\", \"mutations\"]].drop_duplicates(\"mutations\").set_index(\"mutations\")\n",
    "des_matrix_mut = des_matrix[~des_matrix.index.str.startswith(\"-\")]\n",
    "des_matrix_wt = des_matrix[des_matrix.index.str.startswith(\"-\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a695c887",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(plotwidth,plotwidth/4)) # 25,6\n",
    "sns.heatmap(des_matrix.T, square=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fef97d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.linalg.cond(des_matrix_mut.drop('undetermined', axis=1))\n",
    "print(np.linalg.cond(des_matrix))\n",
    "print(np.linalg.cond(des_matrix[[\"BA.1\", \"BA.2\", \"BA.4\", \"BA.5\"]]))\n",
    "print(np.linalg.cond(des_matrix[[i for i in des_matrix.columns if i not in [\"BA.1\", \"BA.2\", \"BA.4\", \"BA.5\", \"undetermined\"]]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2770304e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,3, figsize=(20,5))\n",
    "\n",
    "common_mut = des_matrix_mut.T.dot(des_matrix_mut)\n",
    "sns.heatmap(common_mut, square=True, cmap=\"viridis\", annot=common_mut, ax=axes[0])\n",
    "axes[0].set_title(\"common mutations\")\n",
    "\n",
    "corr_mut = (des_matrix_mut).corr()\n",
    "sns.heatmap(corr_mut, square=True, cmap=\"viridis\", annot=corr_mut, ax=axes[1], fmt=\".1g\")\n",
    "axes[1].set_title(\"correlation\")\n",
    "\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "jac_sim = 1 - pairwise_distances(des_matrix_mut.T, metric = \"hamming\")\n",
    "jac_sim = pd.DataFrame(jac_sim, index=des_matrix_mut.columns, columns=des_matrix_mut.columns)\n",
    "sns.heatmap(jac_sim, square=True, cmap=\"viridis\", annot=jac_sim, ax=axes[2])\n",
    "axes[2].set_title(\"jaccard similarity ((A∩B)/(A∪B))\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e42eb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "preproc.df_tally[preproc.df_tally.proto == \"v41\"].date.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd71359",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_conds_df = []\n",
    "for proto in preproc.df_tally.proto.unique(): \n",
    "\n",
    "    t_df_tally_zh = preproc.df_tally[preproc.df_tally.location == \"Zürich (ZH)\"]\n",
    "    t_df_tally_zh = t_df_tally_zh[t_df_tally_zh.proto == proto]\n",
    "\n",
    "    conds = []\n",
    "    for date in  t_df_tally_zh.date.unique():\n",
    "        des_matrix = t_df_tally_zh[\n",
    "            (t_df_tally_zh.date == date) & \n",
    "            (t_df_tally_zh[\"cov\"] >= 5)][variants_list + [\"undetermined\", \"mutations\"]].drop_duplicates(\"mutations\").set_index(\"mutations\")\n",
    "        des_matrix_mut = des_matrix[~des_matrix.index.str.startswith(\"-\")]\n",
    "        des_matrix_wt = des_matrix[des_matrix.index.str.startswith(\"-\")]\n",
    "        \n",
    "        jac_sim = 1 - pairwise_distances(des_matrix_mut[[\"BA.1\", \"BA.2\", \"BA.4\", \"BA.5\"]].T, metric = \"hamming\")\n",
    "        jac_sim = pd.DataFrame(jac_sim)\n",
    "        jac_arr = jac_sim.values\n",
    "        np.fill_diagonal(jac_arr, np.nan)\n",
    "        maxjac = np.nanmax(jac_arr)\n",
    "        \n",
    "        corr_mut = (des_matrix_mut).corr()\n",
    "        corr_arr = corr_mut.values\n",
    "        np.fill_diagonal(corr_arr, np.nan)\n",
    "        maxcorr = np.nanmax(corr_arr)\n",
    "\n",
    "        \n",
    "        conds.append({\"n_mut\":des_matrix_mut.shape[0],\n",
    "                      \"cond_number\":np.linalg.cond(des_matrix),\n",
    "                      \"cond_number_omicron\":np.linalg.cond(des_matrix[[\"BA.1\", \"BA.2\", \"BA.4\", \"BA.5\"]]), \n",
    "                      \"max_jac\":maxjac, \n",
    "                      \"max_corr\":maxcorr\n",
    "                     })\n",
    "        \n",
    "        \n",
    "    conds_df = pd.DataFrame(\n",
    "        conds,\n",
    "        index=t_df_tally_zh.date.unique()\n",
    "    )\n",
    "    conds_df[\"proto\"] = proto\n",
    "    all_conds_df.append(conds_df)\n",
    "    # print(np.linalg.cond(des_matrix_mut.drop('undetermined', axis=1)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6d4ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_df_tally_zh[\"proto\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcae59c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,3,figsize=(18,5))\n",
    "\n",
    "all_conds_df_conc = pd.concat(all_conds_df)\n",
    "all_conds_df_conc = all_conds_df_conc.reset_index()\n",
    "all_conds_df_conc\n",
    "g = sns.lineplot(\n",
    "    x=all_conds_df_conc[\"index\"],\n",
    "    y=all_conds_df_conc[\"cond_number_omicron\"], \n",
    "    hue = all_conds_df_conc[\"proto\"], \n",
    "    ax=axes[0]\n",
    ")\n",
    "axes[0].set_title(\"condition number\")\n",
    "\n",
    "g.set_ylim(bottom=5, top=20)\n",
    "g.set_xlim(left=np.datetime64(\"2021-12-01\"))\n",
    "g.set_yscale(\"log\")\n",
    "\n",
    "\n",
    "i = sns.lineplot(\n",
    "    x=all_conds_df_conc[\"index\"],\n",
    "    y=all_conds_df_conc[\"max_corr\"], \n",
    "    hue = all_conds_df_conc[\"proto\"], \n",
    "    ax=axes[1]\n",
    ")\n",
    "# h.set_ylim(top=20)\n",
    "i.set_xlim(left=np.datetime64(\"2021-12-01\"))\n",
    "axes[1].set_title(\"max correlation\")\n",
    "\n",
    "\n",
    "h = sns.lineplot(\n",
    "    x=all_conds_df_conc[\"index\"],\n",
    "    y=all_conds_df_conc[\"max_jac\"], \n",
    "    hue = all_conds_df_conc[\"proto\"], \n",
    "    ax=axes[2]\n",
    ")\n",
    "# h.set_ylim(top=20)\n",
    "h.set_xlim(left=np.datetime64(\"2021-12-01\"))\n",
    "axes[2].set_title(\"max jaccard sim\")\n",
    "\n",
    "\n",
    "\n",
    "# sns.lineplot(x=conds_df.index, y=conds_df[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3dd46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_df_tally_zh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dabd59da",
   "metadata": {},
   "source": [
    "# Do piecewise deconvolution with diff variant, bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a0f861",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "with open(r'./WwDec/config.yaml', 'r') as file:\n",
    "    conf_yaml = yaml.load(file,  Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ecbf4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_mutations(df_city1, mutations):\n",
    "    \"\"\"\n",
    "    Function to resample mutations by replacement (preserving mutation-complement pairs). \n",
    "    Returns a copy of the DataFrame with <resample_value> column indicating how many times the mutation was in the resample.\n",
    "    \"\"\"\n",
    "\n",
    "    # resample indices of mutations with replacement (warning: high is one above actual high!\n",
    "    rand_idcs = np.random.randint(0, high=int(len(mutations)/2), size=int(len(mutations)/2))\n",
    "    # for all mutations, count how many times they appear in the resample (0, 1, 2 ...)\n",
    "    resamples_counts = np.bincount(rand_idcs, minlength=int(len(mutations)/2))\n",
    "    # make a dict of {mutation : occurences in the resample} pairs\n",
    "    resample_coeff_dict = dict(zip(mutations, np.concatenate([resamples_counts, resamples_counts])))\n",
    "    # make a column with coefficients for how many times a row should be accounted for according to the resample\n",
    "    df_sampled = df_city1.copy()\n",
    "    df_sampled.loc[:,\"resample_value\"] = df_sampled.mutations.map(resample_coeff_dict)\n",
    "    \n",
    "    return df_sampled, rand_idcs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f275062d",
   "metadata": {},
   "source": [
    "## Do it with linear reg / MSE error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8266c9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "np.random.seed(42)\n",
    "n_boot = 100\n",
    "linear_deconv2 = []\n",
    "\n",
    "for city in tqdm(cities_list):\n",
    "    print(city)\n",
    "    temp_df = preproc.df_tally[preproc.df_tally[\"location\"] == city]\n",
    "    for boot in tqdm(range(n_boot)):\n",
    "        temp_dfb = resample_mutations(temp_df, temp_df.mutations.unique())[0]\n",
    "        for idx, mindate in enumerate(list(conf_yaml[\"var_dates\"].keys())):\n",
    "            temp_df2 = temp_dfb[temp_dfb.date >= mindate]\n",
    "            if idx < len(conf_yaml[\"var_dates\"]) - 1: \n",
    "                temp_df2 = temp_df2[temp_df2.date < list(conf_yaml[\"var_dates\"].keys())[idx+1]]\n",
    "            if temp_df2.size == 0:\n",
    "                continue\n",
    "\n",
    "            t_kdec = KernelDeconv(\n",
    "                temp_df2[conf_yaml[\"var_dates\"][mindate] + [\"undetermined\"]],\n",
    "                temp_df2[\"frac\"],\n",
    "                temp_df2[\"date\"],\n",
    "                weights=temp_df2[\"resample_value\"],\n",
    "                kernel=GaussianKernel(10),\n",
    "                reg=NnlsReg(),\n",
    "                confint=NullConfint()\n",
    "            )\n",
    "            t_kdec = t_kdec.deconv_all()\n",
    "            res = t_kdec.renormalize().fitted\n",
    "            res[\"city\"] = city\n",
    "            linear_deconv2.append(res)\n",
    "linear_deconv2_df = pd.concat(linear_deconv2)\n",
    "linear_deconv2_df = linear_deconv2_df.fillna(0)\n",
    "\n",
    "# backup data\n",
    "linear_deconv2_df.to_csv(\"linear_deconv2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ce880a",
   "metadata": {},
   "source": [
    "### aggregate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0236f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_deconv2_df = pd.concat(linear_deconv2)\n",
    "linear_deconv2_df = linear_deconv2_df.fillna(0)\n",
    "\n",
    "linear_deconv2_df_flat = linear_deconv2_df.melt(\n",
    "    id_vars=\"city\",\n",
    "    value_vars=[i for i in variants_list if i in linear_deconv2_df.columns] + [\"undetermined\"],\n",
    "    var_name=\"variant\",\n",
    "    value_name=\"frac\",\n",
    "    ignore_index=False,\n",
    ")\n",
    "\n",
    "linear_deconv2_df_agg = linear_deconv2_df_flat.reset_index().groupby([\"city\", \"index\", \"variant\"]).agg(\n",
    "    [np.mean,\n",
    "     lambda x: np.quantile(x, q=0.025),\n",
    "     lambda x: np.quantile(x, q=0.975)]\n",
    ").reset_index()\n",
    "linear_deconv2_df_agg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bca2ef",
   "metadata": {},
   "source": [
    "### plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0a5d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(plotwidth, plotwidth/2), sharex=True)\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, city in enumerate(linear_deconv2_df.city.unique()):\n",
    "    axes[i].set_title(city)\n",
    "    \n",
    "    for var in linear_deconv2_df_agg[\"variant\"].unique():\n",
    "        tt_df = linear_deconv2_df_agg[(linear_deconv2_df_agg[\"variant\"] == var) & (linear_deconv2_df_agg[\"city\"] == city)].reset_index()\n",
    "        g = sns.lineplot(\n",
    "            x=tt_df[\"index\"], \n",
    "            y=tt_df[\"frac\"][\"mean\"], \n",
    "            hue=tt_df[\"variant\"],\n",
    "            ax = axes[i], \n",
    "            palette = color_map\n",
    "        )\n",
    "        g.get_legend().remove()\n",
    "        axes[i].fill_between(\n",
    "            x=tt_df[\"index\"], \n",
    "            y1=tt_df[\"frac\"][\"<lambda_0>\"], \n",
    "            y2=tt_df[\"frac\"][\"<lambda_1>\"],\n",
    "            alpha = 0.2,\n",
    "            #color=\"grey\"\n",
    "            color=color_map[var],\n",
    "        )\n",
    "handles, labels = axes[i].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc='lower center', ncol=len(labels), bbox_to_anchor=(0.5,0.05))\n",
    "fig.suptitle(f'Gaussian Kernel Deconvolution ($k=10$)')\n",
    "# plt.savefig(os.path.join(plots_dir, f\"combined-linear.pdf\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eddb2264",
   "metadata": {},
   "source": [
    "### covSPECTRUM export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028d79da",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_data={ }\n",
    "\n",
    "cities_uniq = linear_deconv2_df.city.unique()\n",
    "var_uniq = linear_deconv2_df_agg[\"variant\"].unique()\n",
    "\n",
    "export_columns = {\n",
    "    ('index',''):\"date\",\n",
    "    ('frac','mean'):\"proportion\",\n",
    "    ('frac','<lambda_0>'):\"proportionLower\",\n",
    "    ('frac','<lambda_1>'):\"proportionUpper\",\n",
    "}\n",
    "\n",
    "for var in tqdm(var_uniq, desc='Variants', position=0):\n",
    "    update_data[rename_variants.get(var, var)] = { }\n",
    "    for city in tqdm(cities_uniq, desc=var, position=1, leave=False):\n",
    "        tt_df = linear_deconv2_df_agg.loc[(linear_deconv2_df_agg[\"variant\"] == var) & (linear_deconv2_df_agg[\"city\"] == city),export_columns.keys()].copy()\n",
    "        tt_df.columns = export_columns.values()\n",
    "        tt_df[\"date\"] = tt_df[\"date\"].astype(\"str\")\n",
    "\n",
    "        update_data[rename_variants.get(var, var)][city] = {\n",
    "            \"timeseriesSummary\": [dict(tt_df.iloc[i,]) for i in range(tt_df.shape[0]) ]\n",
    "        }\n",
    "\n",
    "import json\n",
    "with open(update_data_lin_file, 'w') as file:\n",
    "     file.write(json.dumps(update_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5e1df8",
   "metadata": {},
   "source": [
    "## With Robust reg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f7d1aa",
   "metadata": {},
   "source": [
    "### Do just one to try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71f28a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "np.random.seed(42)\n",
    "robust_deconv_short = []\n",
    "\n",
    "for city in [cities_list[1]]:\n",
    "    print(city)\n",
    "    temp_df = preproc.df_tally[preproc.df_tally[\"location\"] == city]\n",
    "    temp_dfb = temp_df\n",
    "    for idx, mindate in enumerate(list(conf_yaml[\"var_dates\"].keys())):\n",
    "        print(mindate)\n",
    "        temp_df2 = temp_dfb[temp_dfb.date >= mindate]\n",
    "        if idx < len(conf_yaml[\"var_dates\"]) - 1: \n",
    "            temp_df2 = temp_df2[temp_df2.date < list(conf_yaml[\"var_dates\"].keys())[idx+1]]\n",
    "        if temp_df2.size == 0:\n",
    "            continue\n",
    "        t_kdec = KernelDeconv(\n",
    "            temp_df2[conf_yaml[\"var_dates\"][mindate] + [\"undetermined\"]],\n",
    "            temp_df2[\"frac\"],\n",
    "            temp_df2[\"date\"],\n",
    "            kernel=GaussianKernel(10),\n",
    "            reg=RobustReg(f_scale=0.01),\n",
    "            confint=NullConfint()\n",
    "        )\n",
    "        t_kdec = t_kdec.deconv_all()\n",
    "        res = t_kdec.renormalize().fitted\n",
    "        res[\"city\"] = city\n",
    "        robust_deconv_short.append(res)\n",
    "robust_deconv_short_df = pd.concat(robust_deconv_short)\n",
    "robust_deconv_short_df = robust_deconv_short_df.fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebcdcc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "robust_deconv_short_df[[i for i in robust_deconv_short_df.columns if i != \"city\"] + [\"undetermined\"]].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420443c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "robust_deconv_short_df[[i for i in robust_deconv_short_df.columns if i != \"city\"] + [\"undetermined\"]].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82e9dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "np.random.seed(42)\n",
    "n_boot = 100\n",
    "robust_deconv2 = []\n",
    "\n",
    "for city in tqdm(cities_list):\n",
    "    print(city)\n",
    "    temp_df = preproc.df_tally[preproc.df_tally[\"location\"] == city]\n",
    "    for boot in tqdm(range(n_boot)):\n",
    "        temp_dfb = resample_mutations(temp_df, temp_df.mutations.unique())[0]\n",
    "        for idx, mindate in enumerate(list(conf_yaml[\"var_dates\"].keys())):\n",
    "            temp_df2 = temp_dfb[temp_dfb.date >= mindate]\n",
    "            if idx < len(conf_yaml[\"var_dates\"]) - 1: \n",
    "                temp_df2 = temp_df2[temp_df2.date < list(conf_yaml[\"var_dates\"].keys())[idx+1]]\n",
    "            if temp_df2.size == 0:\n",
    "                continue\n",
    "            t_kdec = KernelDeconv(\n",
    "                temp_df2[conf_yaml[\"var_dates\"][mindate] + [\"undetermined\"]],\n",
    "                temp_df2[\"frac\"],\n",
    "                temp_df2[\"date\"],\n",
    "                weights=temp_df2[\"resample_value\"],\n",
    "                kernel=GaussianKernel(10),\n",
    "                reg=RobustReg(f_scale=0.01),\n",
    "                confint=NullConfint()\n",
    "            )\n",
    "            t_kdec = t_kdec.deconv_all(min_tol=1e-3) # min tol changed from default\n",
    "            res = t_kdec.renormalize().fitted\n",
    "            res[\"city\"] = city\n",
    "            robust_deconv2.append(res)\n",
    "robust_deconv2_df = pd.concat(robust_deconv2)\n",
    "robust_deconv2_df = robust_deconv2_df.fillna(0)\n",
    "\n",
    "\n",
    "# backup data\n",
    "robust_deconv2_df.to_csv(\"robust_deconv2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd1e7d3",
   "metadata": {},
   "source": [
    "### aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666d6a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "robust_deconv2_df = pd.concat(robust_deconv2)\n",
    "robust_deconv2_df = robust_deconv2_df.fillna(0)\n",
    "\n",
    "robust_deconv2_df_flat = robust_deconv2_df.melt(\n",
    "    id_vars=\"city\",\n",
    "    value_vars=[i for i in variants_list if i in robust_deconv2_df.columns] + [\"undetermined\"],\n",
    "    var_name=\"variant\",\n",
    "    value_name=\"frac\",\n",
    "    ignore_index=False,\n",
    ")\n",
    "\n",
    "robust_deconv2_df_agg = robust_deconv2_df_flat.reset_index().groupby([\"city\", \"index\", \"variant\"]).agg(\n",
    "    [np.mean,\n",
    "     lambda x: np.quantile(x, q=0.025),\n",
    "     lambda x: np.quantile(x, q=0.975)]\n",
    ").reset_index()\n",
    "robust_deconv2_df_agg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9463b24d",
   "metadata": {},
   "source": [
    "### plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db10b03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(plotwidth, plotwidth/2), sharex=True)\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, city in enumerate(robust_deconv2_df_agg.city.unique()):\n",
    "    axes[i].set_title(city)\n",
    "    \n",
    "    for var in robust_deconv2_df_agg[\"variant\"].unique():\n",
    "        tt_df = robust_deconv2_df_agg[(robust_deconv2_df_agg[\"variant\"] == var) & (robust_deconv2_df_agg[\"city\"] == city)]\n",
    "        g = sns.lineplot(\n",
    "            x=tt_df[\"index\"], \n",
    "            y=tt_df[\"frac\"][\"mean\"], \n",
    "            hue=tt_df[\"variant\"],\n",
    "            ax = axes[i], \n",
    "            palette = color_map\n",
    "        )\n",
    "        g.get_legend().remove()\n",
    "        axes[i].fill_between(\n",
    "            x=tt_df[\"index\"], \n",
    "            y1=tt_df[\"frac\"][\"<lambda_0>\"], \n",
    "            y2=tt_df[\"frac\"][\"<lambda_1>\"],\n",
    "            alpha = 0.2,\n",
    "            #color=\"grey\",\n",
    "            color=color_map[var],\n",
    "        )\n",
    "handles, labels = axes[i].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc='lower center', ncol=len(labels), bbox_to_anchor=(0.5,0.05))\n",
    "fig.suptitle(f'Robust Piecewise Gaussian Kernel Deconvolution ($k=10$, $f=0.01$)')\n",
    "plt.savefig(os.path.join(plots_dir, f\"combined-robust.pdf\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9738b71",
   "metadata": {},
   "source": [
    "### covSPECTRUM export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d36a4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_data={ }\n",
    "\n",
    "cities_uniq = robust_deconv2_df.city.unique()\n",
    "var_uniq = robust_deconv2_df_agg[\"variant\"].unique()\n",
    "\n",
    "export_columns = {\n",
    "    ('index',''):\"date\",\n",
    "    ('frac','mean'):\"proportion\",\n",
    "    ('frac','<lambda_0>'):\"proportionLower\",\n",
    "    ('frac','<lambda_1>'):\"proportionUpper\",\n",
    "}\n",
    "\n",
    "for var in tqdm(var_uniq, desc='Variants', position=0):\n",
    "    update_data[rename_variants.get(var, var)] = { }\n",
    "    for city in tqdm(cities_uniq, desc=var, position=1, leave=False):\n",
    "        tt_df = robust_deconv2_df_agg.loc[(robust_deconv2_df_agg[\"variant\"] == var) & (robust_deconv2_df_agg[\"city\"] == city),export_columns.keys()].copy()\n",
    "        tt_df.columns = export_columns.values()\n",
    "        tt_df[\"date\"] = tt_df[\"date\"].astype(\"str\")\n",
    "\n",
    "        update_data[rename_variants.get(var, var)][city] = {\n",
    "            \"timeseriesSummary\": [dict(tt_df.iloc[i,]) for i in range(tt_df.shape[0]) ]\n",
    "        }\n",
    "\n",
    "import json\n",
    "with open(update_data_rob_file, 'w') as file:\n",
    "     file.write(json.dumps(update_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740b455b",
   "metadata": {},
   "source": [
    "## Robust reg but without smoothing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca96e431",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "np.random.seed(42)\n",
    "robust_deconv2 = []\n",
    "\n",
    "for city in tqdm(cities_list):\n",
    "    print(city)\n",
    "    temp_df = preproc.df_tally[preproc.df_tally[\"location\"] == city]\n",
    "    temp_dfb = temp_df\n",
    "    for idx, mindate in enumerate(list(conf_yaml[\"var_dates\"].keys())):\n",
    "        temp_df2 = temp_dfb[temp_dfb.date >= mindate]\n",
    "        if idx < len(conf_yaml[\"var_dates\"]) - 1: \n",
    "            temp_df2 = temp_df2[temp_df2.date < list(conf_yaml[\"var_dates\"].keys())[idx+1]]\n",
    "        if temp_df2.size == 0:\n",
    "            continue\n",
    "        t_kdec = KernelDeconv(\n",
    "            temp_df2[conf_yaml[\"var_dates\"][mindate] + [\"undetermined\"]],\n",
    "            temp_df2[\"frac\"],\n",
    "            temp_df2[\"date\"],\n",
    "            kernel=GaussianKernel(0.0001),\n",
    "            reg=RobustReg(f_scale=0.01),\n",
    "            confint=NullConfint()\n",
    "        )\n",
    "        t_kdec = t_kdec.deconv_all(min_tol=1e-3)\n",
    "        res = t_kdec.renormalize().fitted\n",
    "        res[\"city\"] = city\n",
    "        robust_deconv2.append(res)\n",
    "robust_deconv2_noisy_df = pd.concat(robust_deconv2)\n",
    "robust_deconv2_noisy_df = robust_deconv2_noisy_df.fillna(0)\n",
    "\n",
    "\n",
    "# backup data\n",
    "robust_deconv2_noisy_df.to_csv(\"robust_deconv2_noisy.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f2446b",
   "metadata": {},
   "outputs": [],
   "source": [
    "robust_deconv2_noisy_df.index.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4d051c",
   "metadata": {},
   "source": [
    "## LS reg without smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56572305",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "np.random.seed(42)\n",
    "linear_deconv3 = []\n",
    "\n",
    "for city in tqdm(cities_list):\n",
    "    print(city)\n",
    "    temp_df = preproc.df_tally[preproc.df_tally[\"location\"] == city]\n",
    "    temp_dfb = temp_df\n",
    "    for idx, mindate in enumerate(list(conf_yaml[\"var_dates\"].keys())):\n",
    "        temp_df2 = temp_dfb[temp_dfb.date >= mindate]\n",
    "        if idx < len(conf_yaml[\"var_dates\"]) - 1: \n",
    "            temp_df2 = temp_df2[temp_df2.date < list(conf_yaml[\"var_dates\"].keys())[idx+1]]\n",
    "        if temp_df2.size == 0:\n",
    "            continue\n",
    "        t_kdec = KernelDeconv(\n",
    "            temp_df2[conf_yaml[\"var_dates\"][mindate] + [\"undetermined\"]],\n",
    "            temp_df2[\"frac\"],\n",
    "            temp_df2[\"date\"],\n",
    "            kernel=GaussianKernel(0.0001),\n",
    "            reg=NnlsReg(),\n",
    "            confint=NullConfint()\n",
    "        )\n",
    "        t_kdec = t_kdec.deconv_all(min_tol=1e-3)\n",
    "        res = t_kdec.renormalize().fitted\n",
    "        res[\"city\"] = city\n",
    "        linear_deconv3.append(res)\n",
    "linear_deconv3_noisy_df = pd.concat(linear_deconv3)\n",
    "linear_deconv3_noisy_df = linear_deconv3_noisy_df.fillna(0)\n",
    "\n",
    "\n",
    "# backup data\n",
    "linear_deconv3_noisy_df.to_csv(\"linear_deconv3_noisy.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b11e032",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(plotwidth, plotwidth/2), sharex=True)\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, city in enumerate(robust_deconv2_noisy_df.city.unique()):\n",
    "    axes[i].set_title(city)\n",
    "    \n",
    "    robust_deconv2_noisy_df[robust_deconv2_noisy_df.city == city].plot(ax=axes[i])\n",
    "# handles, labels = axes[i].get_legend_handles_labels()\n",
    "# fig.legend(handles, labels, loc='lower center', ncol=len(labels), bbox_to_anchor=(0.5,0.05))\n",
    "# fig.suptitle(f'Robust Piecewise Gaussian Kernel Deconvolution ($k=10$, $f=0.01$)')\n",
    "# plt.savefig(os.path.join(plots_dir, f\"combined-robust.pdf\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778e33f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(variants_pangolin.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9694d287",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bio1",
   "language": "python",
   "name": "bio1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
